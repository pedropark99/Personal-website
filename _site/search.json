[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "Hey! I‚Äôm Pedro Duarte Faria. A brazilian economist, data analyst and software enginner, working mainly with R, SQL, Python and Apache Spark. I do a lot of data analysis these days, but I do love teaching software development and building open-source software too."
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "About Me",
    "section": "Experience",
    "text": "Experience\nData Analyst, Take Blip, May 2021 - present.\nResearch engineering Intern, Jo√£o Pinheiro Foundation, August 2019 - March 2021.\nBusiness Intelligence Intern, Beltech, June 2019 - August 2019."
  },
  {
    "objectID": "about.html#projects",
    "href": "about.html#projects",
    "title": "About Me",
    "section": "Projects",
    "text": "Projects\nI‚Äôm the author of R package {figma}, and, a technical and introductory book about the R language. I have made some contributions to R package {knitr} too, which is one of the biggest open-source projects in the R community."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About Me",
    "section": "Education",
    "text": "Education\nFederal University of Ouro Preto - UFOP, Brazil\nEconomics, B.S., March 2017 - February 2022."
  },
  {
    "objectID": "donate.html",
    "href": "donate.html",
    "title": "Donate or Sponsor Me",
    "section": "",
    "text": "Payment methods\nCurrently, I only support direct transfers made via Pix. Which is a brazilian payment method available in most banks operating in the Brazilian market.\n\n\n\n\n\nCopy and paste it\nYou can click in the button to copy my Pix key to your clipboard:\n\nCopy Pix Key\n\n\n\nScan a QR Code\nOr, if you prefer, you can get my Pix key with this QR Code:"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hi there üñêÔ∏è!",
    "section": "",
    "text": "In this page, you can quickly scan through my latest published books üìö and blog posts üìå. But, if you prefer, you can read a quick resume of me and my work in the About Me section too. Be free to contact me via email if you have an interesting proposal üòâ. If you want to support me monetarily, you can send me a Pix (more info in the Donate or Sponsor Me section)."
  },
  {
    "objectID": "index.html#my-books",
    "href": "index.html#my-books",
    "title": "Hi there üñêÔ∏è!",
    "section": "My books",
    "text": "My books\n\n\n\n\n\n\n\n\n\n\nIntroduction to pyspark\n\n\nThis book offers a introduction on how to build Spark applications using the pyspark python package\n\n\n\nPedro Duarte Faria\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntrodu√ß√£o √† Linguagem R: seus fundamentos e sua pr√°tica\n\n\nEste livro oferece uma descri√ß√£o profunda sobre os fundamentos da linguagem R, e como eles se aplicam no contexto da an√°lise de dados.\n\n\n\nPedro Duarte Faria\n\n\nDec 1, 2022\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#posts",
    "href": "index.html#posts",
    "title": "Hi there üñêÔ∏è!",
    "section": "Posts",
    "text": "Posts\n\n\n\n\n\n\n\n\n\n\nWhat I learned from developing my first Python package\n\n\nIn this post, I want to share some of the challenges, and what I learned from developing my first Python package published at PyPI\n\n\n\nPedro Duarte Faria\n\n\nJan 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJOINs s√£o importantes fontes de duplica√ß√µes em seus dados\n\n\nSe os seus dados crescerem de forma repentina, sem explica√ß√£o aparente, verifique se os seus JOINs s√£o a fonte desse problema\n\n\n\nPedro Duarte Faria\n\n\nJan 10, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNovidades da 4¬∞ edi√ß√£o de Introdu√ß√£o √† Linguagem R: seus fundamentos e sua pr√°tica\n\n\nEsta quarta edi√ß√£o traz algumas melhorias que buscam manter um dos principais objetivos deste livro, que √© ser uma refer√™ncia moderna, introdut√≥ria e t√©cnica sobre a‚Ä¶\n\n\n\nPedro Duarte Faria\n\n\nDec 26, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroducing the {spark_map} Python package\n\n\nWith this package, you can easily apply a function over multiple columns of a Spark DataFrame\n\n\n\nPedro Duarte Faria\n\n\nDec 21, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nErro de mem√≥ria no Power BI Online? Hora de repensar o seu dashboard\n\n\nNeste post explico como um erro de mem√≥ria no Power BI Online pode ser um forte sinal de que voc√™ est√° errando no design de seu dashboard\n\n\n\nPedro Duarte Faria\n\n\nDec 14, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroducing the {figma} R package\n\n\nWith this package, you can access the Figma API to bring your design files to R üé®!\n\n\n\nPedro Duarte Faria\n\n\nNov 6, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNovidades da 3¬∞ edi√ß√£o de Introdu√ß√£o √† Linguagem R: seus fundamentos e sua pr√°tica\n\n\nUma grande reforma sobre a obra foi feita para esta nova edi√ß√£o. Como resultado, temos seis novos cap√≠tulos para voc√™!\n\n\n\nPedro Duarte Faria\n\n\nApr 6, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNovidades da 2¬∞ edi√ß√£o de Introdu√ß√£o √† Linguagem R: seus fundamentos e sua pr√°tica\n\n\nEsse post descreve as novas adi√ß√µes √† segunda edi√ß√£o do livro Introdu√ß√£o √† Linguagem R: seus fundamentos e sua pr√°tica. Fatores (factors); Datas e vari√°veis de tempo‚Ä¶\n\n\n\nPedro Duarte Faria\n\n\nMay 26, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRecipient table and source table\n\n\nA different (maybe crazy) view on how to teach/explain Outer joins to students\n\n\n\nPedro Duarte Faria\n\n\nJan 2, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTabela destinat√°ria e tabela fonte\n\n\nUm vis√£o diferente (talvez maluca) sobre como ensinar/explicar Outer joins para seus alunos\n\n\n\nPedro Duarte Faria\n\n\nJan 2, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResultados do Formul√°rio de Pesquisa de Interesse - Curso Introdut√≥rio de R\n\n\nUma r√°pida an√°lise sobre o impacto e as sugest√µes fornecidas ao Curso Introdut√≥rio de R\n\n\n\nPedro Duarte Faria\n\n\nOct 17, 2020\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2020/2020-10-17-formulario-pesquisa/pt/index.html",
    "href": "posts/2020/2020-10-17-formulario-pesquisa/pt/index.html",
    "title": "Resultados do Formul√°rio de Pesquisa de Interesse - Curso Introdut√≥rio de R",
    "section": "",
    "text": "Esse post faz parte de um projeto meu, de um Curso Introdut√≥rio de R. Esse projeto j√° tem um ano, que venho aperfei√ßoando-o, e a primeira vez que ele foi posto em pr√°tica (ou seja, a primeira vez que dei um curso da linguagem) foi no instituto de pesquisa onde trabalho, a Funda√ß√£o Jo√£o Pinheiro1. Foi um momento muito proveitoso, pois uma das melhores formas de se aprender uma mat√©ria, √© tentando ensin√°-la para outras pessoas.\nAprimorei e venho aprimorando constatemente o meu conhecimento da linguagem R, e agora, uma nova oportunidade de ensinar essa linguagem, surgiu atrav√©s de um convite da CORECON-MG2 Acad√™mico. Com a ideia de compreendermos melhor as prefer√™ncias do potencial p√∫blico desse curso, n√≥s lan√ßamos um formul√°rio de pesquisa no dia 10/10/2020.\nNeste post, estarei analisando rapidamente as respostas que coletamos por esse formul√°rio. Por motivos √≥bvios, as informa√ß√µes pessoais daqueles que responderam ao formul√°rio, foram omitidas nesse artigo.\n\nTivemos inclusive pessoas de outros pa√≠ses!\nNo momento em que estou montando essa an√°lise, tivemos no total, 122 respostas ao formul√°rio. Mesmo sendo um n√∫mero relativamente pequeno de pessoas, atingimos os mais diversos locais do pa√≠s, abrangendo todas as cinco regi√µes do pa√≠s.\n\nnrow(respostas)\n\n[1] 122\nAs respostas ao formul√°rio n√£o tinham um padr√£o bem definido, e por isso algumas respostas tiveram que ser ajustadas. Ao final desse ajuste, percebemos que pessoas de 61 institui√ß√µes diferentes responderam ao formul√°rio.\n\nnrow(instituicoes)\n\n[1] 61\nA maior parte das institui√ß√µes √†s quais os respondentes pertenciam, est√£o localizadas na regi√£o Sudeste, com 22 institui√ß√µes. O Nordeste vem logo em seguida, com 16 insitui√ß√µes. Agora, as institui√ß√µes que n√£o foram designadas para alguma regi√£o (NA), s√£o na verdade institui√ß√µes de fora do Brasil. Isso significa que tivemos 5 respostas vindas de outros pa√≠ses, ao formul√°rio de interesse no curso.\n\nlibrary(tidyverse)\n\ninstituicoes %>% \n  group_by(Regiao) %>% \n  summarise(contagem = n())\n\n# A tibble: 6 √ó 2\n  Regiao       contagem\n  <chr>           <int>\n1 Centro Oeste        3\n2 Nordeste           15\n3 Norte               9\n4 Sudeste            22\n5 Sul                 7\n6 NA                  5\nA maioria das pessoas que responderam ao formul√°rio, provinham de institui√ß√µes localizadas no estado Minas Gerais. Grande parte das respostas foram da UFOP (que √© a institui√ß√£o na qual estudo), totalizando 22 respostas. Al√©m disso, n√£o recebemos respostas de alguns estados, que est√£o marcados em cinza no gr√°fico abaixo:\n\nlibrary(geobr)\nbrasil <- read_state()\n\n\nresp_sum <- respostas %>%\n  select(Regiao, Instituicao, abbrev, Estado) %>%\n  group_by(Estado, Regiao) %>%\n  summarise(contagem = n())\n\nbrasil <- brasil %>%\n  left_join(resp_sum, by = c(\"name_state\" = \"Estado\"))\n\nggplot(data = brasil) +\n  geom_sf(aes(fill = Regiao)) +\n  stat_sf_coordinates(\n    aes(label = contagem),\n    geom = \"text\"\n  ) +\n  theme_void() +\n  labs(\n    title = \"N√∫mero de respostas provenientes de cada estado brasileiro\",\n    fill = \"Regi√£o\"\n  )\n\n\nTalvez o mais impressionante de tudo isso, √© que tivemos pessoas de outros pa√≠ses interessadas no curso. Cada um desses outros pa√≠ses obtiveram apenas uma assinatura, mas mesmo assim, √© no m√≠nimo interessante ver o qu√£o longe fomos. Os pa√≠ses atingidos (fora o Brasil), e as respectivas institui√ß√µes dos respondentes foram: Venezuela (Universidad de Carabobo); Cuba (Universidad de la Havana); Mo√ßambique (ISRI - Instituto Superior De Rela√ß√µes Internacionais); e Peru (Universidad Nacional de Ingeniaria); Portugal (Universidade de Lisboa).\n\ncores <- c(\n  \"Brazil\" = \"#F8766D\",\n  \"Cuba\" = \"#BB9D00\",\n  \"Mozambique\" = \"#7CAE00\",\n  \"Venezuela\" = \"#00A5FF\",\n  \"Peru\" = \"#E76BF3\",\n  \"Portugal\" = \"#4fc953\",\n  \"N√£o foi atingido\" = \"#d4d4d4\"\n)\n\nworld$cores <- unname(cores[world$marca])\n\nggplot(data = world) +\n  geom_sf(aes(fill = cores)) +\n  coord_sf(xlim = c(-100, 50), ylim = c(-60, 40)) +\n  theme_void() +\n  labs(\n    title = \"Pa√≠ses atingidos pelo formul√°rio\",\n    fill = \"Pa√≠s de refer√™ncia\"\n  ) +\n  theme(legend.position = \"bottom\") +\n  scale_fill_identity(\n    guide = \"legend\",\n    labels = names(cores),\n    breaks = unname(cores)\n  )\n\n\n\n\nAssuntos requisitados\nO R √© uma linguagem que foi criada por estat√≠sticos, e por isso, √© uma linguagem especializada em an√°lise de dados e estat√≠stica. Com isso, n√£o √© nenhuma surpresa que Econometria e An√°lise de S√©ries Temporais, tenham sido as principais sugest√µes e assuntos requisitados para o curso, pelas pessoas que responderam o formul√°rio.\n\nlibrary(wordcloud)\nlibrary(RColorBrewer)\n\nassuntos <- respostas %>%\n  filter(!is.na(Sugestao)) %>%\n  group_by(Sugestao) %>%\n  count() %>%\n  arrange(n)\n\ncor <- brewer.pal(6, \"Dark2\")\nnames(cor) <- c(\"1\", \"3\", \"5\", \"8\", \"2\", \"4\")\nassuntos$color <- cor[as.character(assuntos$n)]\n\n\nwordcloud(\n  words = assuntos$Sugestao,\n  freq = assuntos$n,\n  min.freq = 1,\n  max.words = 200,\n  ordered.colors = TRUE,\n  rot.per = 0.35,\n  use.r.layout = FALSE,\n  scale = c(2,0.5),\n  colors = assuntos$color\n)\n\n\n\n\n\n\n\n\n√Åreas dos respondentes\nA enorme maioria das pessoas que responderam eram alunos de gradua√ß√£o, ou bachareis j√° formados. Como pode ser observado logo abaixo, tivemos tamb√©m algumas pessoas com algum n√≠vel de p√≥s-gradua√ß√£o.\n\ntable(respostas$Nivel)\n\nDoutorado Gradua√ß√£o  Mestrado \n        4       113         5 \nCuriosamente, das 9 pessoas que possu√≠am ou estavam fazendo p√≥s-gradua√ß√£o (mestrado ou doutorado), 6 eram de alguma √°rea da Sa√∫de ou das Ci√™ncias Biol√≥gicas. Apenas uma dessas 9 pessoas, pertencia a √°rea de Economia. Esse resultado faz sentido, visto que a linguagem R tem se expandido muito em algumas √°reas como a epidemiologia e principalmente em an√°lise gen√©tica, atrav√©s de um conjunto de pacotes como o Bioconductor3.\nDe qualquer maneira, olhando para o n√∫mero geral de respondentes, a grande maioria do p√∫blico atingido pelo formul√°rio, foram graduandos (ou bachareis j√° formados) em Economia, totalizando 65 pessoas.\n\nrespostas %>% \n  filter(Curso == \"Economia\") %>% \n  nrow()\n\n[1] 65\nQuanto √†s 52 pessoas restantes que n√£o pertencem √† area de Economia, as √°reas atingidas foram bem diversas. Foram 5 pessoas de Agronomia e 4 pessoas de Geologia. As demais √°reas marcadas em laranja abaixo, correspondem a 2 pessoas, enquanto todas as outras em ciano obtiveram apenas 1 respondente.\n\nareas <- respostas %>% \n  filter(Curso != \"Economia\") %>% \n  group_by(Curso) %>% \n  count() %>% \n  arrange(n)\n\ncor <- brewer.pal(5, \"Dark2\")\nnames(cor) <- unique(areas$n)\nareas$color <- unname(cor[as.character(areas$n)])\n\nwordcloud(\n  words = areas$Curso,\n  freq = areas$n,\n  min.freq = 1,\n  max.words = 200,\n  ordered.colors = TRUE,\n  rot.per = 0.35,\n  use.r.layout = FALSE,\n  scale = c(2,0.5),\n  color = areas$color\n)\n\n\n\n\n\n\n\n\n\nFootnotes\n\n\nhttp://novosite.fjp.mg.gov.br/‚Ü©Ô∏é\nConselho Regional de Economia Acad√™mico de Minas Gerais:http://corecon-mg.org.br/academico/‚Ü©Ô∏é\nhttps://www.bioconductor.org/‚Ü©Ô∏é"
  },
  {
    "objectID": "posts/2021/2021-01-02-tabela-destinataria-fonte/en/index.html",
    "href": "posts/2021/2021-01-02-tabela-destinataria-fonte/en/index.html",
    "title": "Recipient table and source table",
    "section": "",
    "text": "Introduction\nOuter joins are a simple topic of understanding for most students. However, this article proposes a second approach on the subject. This approach was built during a recent reformulation of the chapter ‚ÄúIntrodu√ß√£o a base de dados relacionais‚Äù, from the book Introdu√ß√£o √† Linguagem R: seus fundamentos e sua pr√°tica. The point of view presented here seeks to be strict, and uses this rigidity as a mechanism that facilitates the student`s memorization of the behaviors in each type of outer join.\n\n\nJoins have direction\nA join operation is nothing more than a union between two tables. But, instead of an union of two tables, we have another option for interpreting the result of this operation. So that to produce a table that represents the union between two tables, we could simply extract all the columns from one of the tables, and insert them into the other table.\nFor example, suppose you have a table A, which contains two columns, called x and y; and a table B, which in turn holds 4 different columns, named x, z, r, and t. Note that one of the columns in table B corresponds to the same column x that we found in table A.\n\nlibrary(tibble)\n\nA <- tibble(\n  x = 1:5,\n  y = round(rnorm(5, 2, 1), 2)\n)\n\nB <- tibble(\n  x = 1:5,\n  z = letters[1:5],\n  r = c(3.5, 2.1, 1, 5.6, 7.2),\n  t = \"tzu\"\n)\n\nIf you want to join tables A and B, you basically want to create a new table, which contains all five columns of these two tables (x, y, z, r and t). Therefore, we could imagine a join process, as if we were extracting all the columns from table B, and inserting all of these columns in table A. Hence, we have the table below as a result:\n\nfull_join(A, B, by = \"x\")\n\n# A tibble: 5 √ó 5\n      x     y z         r t    \n  <int> <dbl> <chr> <dbl> <chr>\n1     1  2.14 a       3.5 tzu  \n2     2  2.61 b       2.1 tzu  \n3     3  2.3  c       1   tzu  \n4     4  4.12 d       5.6 tzu  \n5     5  1.98 e       7.2 tzu  \n\n\nWith this, we are creating the idea that a join always has a direction. In other words, we first extract the columns from table B, and then we add those columns to table A. Note that we are always starting from table B towards table A.\n\n\n\n\n\n\n\nRecipient table and source table\nFrom this perspective, we can interpret that, in a join, we are bringing all the columns of a secondary table into our main table (or our table of interest). We have the option to call these tables :source table (secondary table) and recipient table (main table). With this, a join always starts at source table and go towards the recipient table.\nThis perspective makes sense with the practice of joins. Because in any analysis, we commonly work with a ‚Äúmain‚Äù table, or a table that contains the key data we‚Äôre analyzing. And when we use some join, we‚Äôre usually bringing columns from other tables into this ‚Äúmain‚Äù table (or ‚Äúrecipient‚Äù table, according to that perspective). So keep in mind that a join always part from the source table toward the recipient table.\n\n\nTypes of outer join\nA natural join (inner join) usually generates a loss of observations from both tables involved in the process. In contrast, a join of type outer (that is, an outer join), seeks to delimit which of the two tables will be preserved in the result. That is, an outer join seeks to keep in the join result, the rows of at least one of the tables involved.\nWe have three main types of outer joins, which are left join, right join and full join. A full join is the simplest to understand, as it seeks to keep all rows of both tables employed. Therefore, even if there is some observation not found in one of the tables, it will be preserved in the final product of the operation.\nHowever, left join and right join seek to keep rows from only one of the tables used in join. At this point, many teachers would say something like: ‚Äúif we want to apply a join between tables A and B, a left join will keep the rows of table A, and a right join will keep the rows of table B‚Äù. Other teachers would still try to say, ‚Äúleft join will keep the table rows on the left, while a right join will keep the table rows to the right‚Äù.\nHowever, some confusion can be easily applied in both alternatives. I mean, a student can easily face the following question: ‚Äúü§î Uhmm‚Ä¶ I don‚Äôt remember very well. Does a left join keep the rows in table A? Or are the rows in table B?‚Äù; or else, ‚Äúü§î Wait! But which of the two tables is on the right side?‚Äù\n\n\nConclusion\nWith this, according to the perspective adopted in this article, we can understand that a left join and a right join seek to keep the rows of the recipient table and the source table, respectively. Thus, when using a right join or a left join, you should ask yourself the following: ‚ÄúDo I want to keep the rows in my main table (recipient table)? Or the secondary table (source table), where I am extracting the new columns from?‚Äù So if you want to keep, for example, the rows in your main table (recipient table), which is what occurs most of the time, you now know that you need to use a left join.\nIn a visual representation, we can reproduce below the initial image of this article, which marks the lines maintained by each of these two types of join."
  },
  {
    "objectID": "posts/2021/2021-01-02-tabela-destinataria-fonte/pt/index.html",
    "href": "posts/2021/2021-01-02-tabela-destinataria-fonte/pt/index.html",
    "title": "Tabela destinat√°ria e tabela fonte",
    "section": "",
    "text": "Introdu√ß√£o\nOuter joins s√£o um t√≥pico de simples compreens√£o para a maioria dos alunos. Entretanto, esse artigo prop√µe uma segunda abordagem sobre o tema. Tal abordagem foi constru√≠da durante uma reformula√ß√£o recente do cap√≠tulo ‚ÄúIntrodu√ß√£o a base de dados relacionais‚Äù do livro Introdu√ß√£o √† Linguagem R: seus fundamentos e sua pr√°tica. O ponto de vista apresentado aqui, busca ser estrito, e utiliza essa rigidez como um mecanismo que facilite a memoriza√ß√£o do aluno sobre os comportamentos de cada tipo de outer join.\n\n\nJoins possuem sentido e dire√ß√£o\nUma opera√ß√£o de join √© nada mais do que uma uni√£o entre duas tabelas. Por outro lado, temos uma outra op√ß√£o de interpreta√ß√£o do resultado dessa opera√ß√£o. De modo que, para produzirmos uma tabela que represente a uni√£o entre duas tabelas, poder√≠amos simplesmente extrair todas as colunas de uma das tabelas, e inser√≠-las na outra tabela.\nPor exemplo, suponha que voc√™ possua uma tabela A, que cont√©m duas colunas, chamadas x e y; e uma tabela B, que por sua vez, guarda 4 colunas diferentes, denominadas x, z, r, e t. Perceba que uma das colunas na tabela B, corresponde a mesma coluna x que encontramos na tabela A.\n\nlibrary(tibble)\n\nA <- tibble(\n  x = 1:5,\n  y = round(rnorm(5, 2, 1), 2)\n)\n\nB <- tibble(\n  x = 1:5,\n  z = letters[1:5],\n  r = c(3.5, 2.1, 1, 5.6, 7.2),\n  t = \"tzu\"\n)\n\nSe voc√™ deseja unir as tabelas A e B, voc√™ basicamente deseja criar uma nova tabela, que cont√©m todas as cinco colunas dessas duas tabelas (x, y, z, r e t). Portanto, poder√≠amos imaginar um processo de join, como se estiv√©ssemos transportando todas as colunas da tabela B, para dentro da tabela A. Dessa maneira, temos a tabela abaixo como resultado:\n\nlibrary(dplyr)\n\n\nfull_join(A, B, by = \"x\")\n\n# A tibble: 5 √ó 5\n      x     y z         r t    \n  <int> <dbl> <chr> <dbl> <chr>\n1     1  1.5  a       3.5 tzu  \n2     2  2.02 b       2.1 tzu  \n3     3  1.34 c       1   tzu  \n4     4  1.24 d       5.6 tzu  \n5     5  2.49 e       7.2 tzu  \n\n\nCom isso, estamos criando a ideia de que um join possui sempre um sentido e uma dire√ß√£o. Em outras palavras, primeiro, extra√≠mos as colunas da tabela B, e em seguida, acrescentamos essas colunas √† tabela A. Repare que estamos sempre partindo da tabela B em dire√ß√£o a tabela A.\n\n\n\n\n\n\n\nTabela destinat√°ria e tabela fonte\nPor essa perspectiva, podemos interpretar que, em um join, estamos trazendo todas as colunas de uma tabela secund√°ria, para dentro de nossa tabela principal (ou a nossa tabela de interesse). Temos a op√ß√£o de chamarmos essas tabelas de: tabela fonte (tabela secund√°ria) e tabela destinat√°ria (tabela principal). Com isso, temos que um join sempre parte da tabela fonte em dire√ß√£o √† tabela destinat√°ria.\nEssa perspectiva faz sentido com a pr√°tica de joins. Pois em qualquer an√°lise, n√≥s comumente trabalhamos com uma tabela ‚Äúprincipal‚Äù, ou uma tabela que cont√©m os principais dados que estamos analisando. E quando utilizamos algum join, estamos geralmente trazendo colunas de outras tabelas para dentro dessa tabela ‚Äúprincipal‚Äù (ou tabela ‚Äúdestinat√°ria‚Äù, segundo essa perspectiva). Por isso, tenha em mente que um join sempre parte da tabela fonte em dire√ß√£o √† tabela destinat√°ria.\n\n\nTipos de outer join\nUm join natural (inner join) usualmente gera uma perda de observa√ß√µes de ambas as tabelas envolvidas no processo. Em contrapartida, um join do tipo outer (isto √©, um outer join), busca delimitar qual das duas tabelas ser√° preservada no resultado. Ou seja, um outer join busca manter as linhas de pelo menos uma das tabelas envolvidas, no resultado do join.\nTemos tr√™s tipos principais de outer joins, que s√£o left join, right join e full join. O full join √© o mais simples de se compreender, pois ele busca manter todas as linhas de ambas as tabelas empregadas. Logo, mesmo que haja alguma observa√ß√£o n√£o encontrada em uma das tabelas, ela ser√° preservada no produto final da opera√ß√£o.\nNo entanto, left join e right join buscam conservar as linhas de apenas uma das tabelas utilizadas no join. Nesse ponto, muitos professores diriam algo como: ‚Äúse temos desejamos aplicar um join entre as tabelas A e B, um left join ir√° manter as linhas da tabela A e um right join vai manter as linhas da tabela B‚Äù. Outros professores ainda tentariam dizer: ‚Äúleft join ir√° manter as linhas da tabela √† esquerda, enquanto um right join vai manter as linhas da tabela √† direita‚Äù.\nPor√©m, certa confus√£o pode ser facilmente aplicada em ambas alternativas. Digo, um aluno pode facilmente enfrentar a seguinte quest√£o: ‚Äúü§î Uhmm‚Ä¶ Eu n√£o me lembro muito bem. Um left join mant√©m as linhas da tabela A? Ou s√£o as linhas da tabela B?‚Äù; ou ent√£o, ‚Äúü§î Pera! Mas qual das duas tabelas est√° a direita?‚Äù.\n\n\nConclus√£o\nCom isso, segundo a perspectiva adotada nesse artigo, podemos entender que, um left join e um right join buscam manter as linhas da tabela destinat√°ria e da tabela fonte, respectivamente. Dessa forma, ao utilizar um right join ou um left join, voc√™ deve se questionar o seguinte: ‚ÄúEu quero manter as linhas de minha tabela principal (tabela destinat√°ria)? Ou da tabela secund√°ria (tabela fonte), de onde estou extraindo as novas colunas?‚Äù. Logo, se voc√™ deseja manter, por exemplo, as linhas de sua tabela principal (tabela destinat√°ria), que √© o que ocorre na maioria das vezes, voc√™ sabe agora que voc√™ precisa utilizar um left join.\nEm uma representa√ß√£o visual, podemos reproduzir abaixo a imagem inicial desse artigo, que marca as linhas mantidas por cada um desses dois tipos de join."
  },
  {
    "objectID": "posts/2021/2021-05-26-2nd-edition-rbook/pt/index.html#adi√ß√£o-de-exerc√≠cios-em-cada-cap√≠tulo",
    "href": "posts/2021/2021-05-26-2nd-edition-rbook/pt/index.html#adi√ß√£o-de-exerc√≠cios-em-cada-cap√≠tulo",
    "title": "Novidades da 2¬∞ edi√ß√£o de Introdu√ß√£o √† Linguagem R: seus fundamentos e sua pr√°tica",
    "section": "Adi√ß√£o de exerc√≠cios em cada cap√≠tulo",
    "text": "Adi√ß√£o de exerc√≠cios em cada cap√≠tulo\nDesde o in√≠cio, o livro se prop√¥s a ser uma refer√™ncia introdut√≥ria e, principalmente, t√©cnica, sobre a linguagem. Isto significa que, o livro n√£o tenta atingir o p√∫blico que procura por algo sucinto e eficiente, mas sim, o p√∫blico iniciante que busca se aprofundar (ou ter uma base mais s√≥lida) em conceitos, m√©todos e outras partes importantes da linguagem.\nApesar desse prop√≥sito, o livro inicialmente n√£o oferece exerc√≠cios, os quais s√£o uma caracter√≠stica essencial de qualquer obra t√©cnica. Por esse motivo, a introdu√ß√£o de exerc√≠cios em cada cap√≠tulo dessa segunda edi√ß√£o, busca ajudar o livro a caminhar para esse prop√≥sito, se tornando uma obra mais consolidada.\nAtualmente, a constru√ß√£o dos exerc√≠cios para cada cap√≠tulo √© a √∫nica parte (dessa nova edi√ß√£o) que ainda est√° em constru√ß√£o. A partir do momento em que essa etapa for finalizada, a segunda edi√ß√£o ser√° lan√ßada para todo o p√∫blico brasileiro."
  },
  {
    "objectID": "posts/2021/2021-05-26-2nd-edition-rbook/pt/index.html#fatores-factors",
    "href": "posts/2021/2021-05-26-2nd-edition-rbook/pt/index.html#fatores-factors",
    "title": "Novidades da 2¬∞ edi√ß√£o de Introdu√ß√£o √† Linguagem R: seus fundamentos e sua pr√°tica",
    "section": "Fatores (factor‚Äôs)",
    "text": "Fatores (factor‚Äôs)\nNo cap√≠tulo 2 do livro, s√£o abordados os quatro tipos de dados b√°sicos da linguagem R. Sendo eles: integer; double; character; e logical. Por√©m, h√° dois outros tipos de dados, que s√£o ‚Äúmais complexos‚Äù, e que tamb√©m s√£o muito importantes hoje em dia. S√£o eles os fatores (ou factor‚Äôs) e os tipos voltados para vari√°veis de tempo (date, POSIXct, POSIXlt).\nFatores s√£o especialmente √∫teis para classificarmos vari√°veis categ√≥ricos. Isto √©, definirmos a ordem de seus ‚Äún√≠veis‚Äù (ou ‚Äúgrupos‚Äù). Dito de outra forma, v√°rias caracter√≠sticas podem ser descritas atrav√©s de uma vari√°vel categ√≥rica, mas nem sempre essas caracter√≠sticas seguem uma ordena√ß√£o num√©rica, ou uma ordem alfab√©tica. Por exemplo, ao dar a sua avalia√ß√£o de um certo governo, voc√™ pode responder ‚ÄúP√©ssimo‚Äù, ‚ÄúRuim‚Äù, ‚ÄúBom‚Äù ou ‚ÄúMuito Bom‚Äù. Perceba pela demonstra√ß√£o abaixo, que caso eu empregue uma ordena√ß√£o alfab√©tica (crescente) sobre as minhas respostas, ‚ÄúBom‚Äù aparece antes de ‚ÄúRuim‚Äù, ‚ÄúP√©ssimo‚Äù e ‚ÄúMuito Bom‚Äù.\n\nrespostas <- c(\"Muito Bom\", \"Muito Bom\", \"Bom\", \"Ruim\", \"P√©ssimo\",\n               \"Bom\", \"Ruim\", \"Ruim\", \"Muito Bom\", \"Ruim\")\nsort(respostas)\n\n [1] \"Bom\"       \"Bom\"       \"Muito Bom\" \"Muito Bom\" \"Muito Bom\" \"P√©ssimo\"  \n [7] \"Ruim\"      \"Ruim\"      \"Ruim\"      \"Ruim\"     \n\n\nCom o uso de fatores, n√≥s podemos definir qual a ordem correta desses diferentes n√≠veis e corrigir esse problema de ordena√ß√£o. Perceba abaixo que a ordena√ß√£o dos valores foi corrigida.\n\nrespostas <- factor(respostas)\nlevels(respostas) <- c(\"P√©ssimo\", \"Ruim\", \"Bom\", \"Muito Bom\")\nsort(respostas)\n\n [1] P√©ssimo   P√©ssimo   Ruim      Ruim      Ruim      Bom       Muito Bom\n [8] Muito Bom Muito Bom Muito Bom\nLevels: P√©ssimo Ruim Bom Muito Bom"
  },
  {
    "objectID": "posts/2021/2021-05-26-2nd-edition-rbook/pt/index.html#vari√°veis-de-tempo",
    "href": "posts/2021/2021-05-26-2nd-edition-rbook/pt/index.html#vari√°veis-de-tempo",
    "title": "Novidades da 2¬∞ edi√ß√£o de Introdu√ß√£o √† Linguagem R: seus fundamentos e sua pr√°tica",
    "section": "Vari√°veis de tempo",
    "text": "Vari√°veis de tempo\nFirmas registram o hor√°rio em que vendas s√£o realizadas, o hor√°rio em que cargas de insumos chegam a suas instala√ß√µes, o tempo de trabalho de seus funcion√°rios, al√©m da evolu√ß√£o de v√°rios de seus indicadores ao longo do tempo. Pois tempo √© dinheiro, e, em uma economia capitalista o dinheiro √© o que faz a diferen√ßa.\nPor essa raz√£o, vari√°veis de tempo s√£o fundamentais em diversas an√°lises de dados e, √© muito importante que voc√™ saiba como trabalhar com elas em qualquer linguagem de programa√ß√£o que voc√™ venha a trabalhar. Por isso, essa √© uma lacuna atual muito importante do livro e, que est√° sendo preenchida nessa segunda edi√ß√£o.\nA linguagem R nos oferece tr√™s tipos principais de dados focados em vari√°veis de tempo, sendo eles: Date, POSIXct, POSIXlt. Al√©m disso, temos ainda um quarto tipo de dado chamado difftime, que busca dar suporte √†s opera√ß√µes aritm√©ticas entre os 3 tipos anteriores. Valores desses tr√™s tipos de dados, s√£o criados a partir das fun√ß√µes as.POSIXct(), as.POSIXlt() e as.Date().\nO tipo Date nos ajuda a armazenar datas no R. Poder√≠amos armazenar datas como simples strings, mas com isso, ter√≠amos uma ordena√ß√£o incorreta dos valores, al√©m da falta de acesso a diversos m√©todos aritm√©ticos e computacionais voltados para esse tipo de dado. Logo, tratar as suas datas por meio do tipo Date pode fazer a diferen√ßa em sua an√°lise.\n\nd <- as.Date(c(\"2020-08-10\", \"2020-08-11\", \"2020-08-12\"))\nd\n\n[1] \"2020-08-10\" \"2020-08-11\" \"2020-08-12\"\n\n\nJ√° o tipo POSIXct √© particularmente √∫til para interpretar datas acompanhadas de um hor√°rio (isto √©, um dado do tipo date-time). Certas transa√ß√µes econ√¥micas precisam ser registradas com um n√≠vel de precis√£o alto. Ou seja, os registros de muitas empresas n√£o se contentam com datas, pois eles tamb√©m necessitam saber o momento exato (ou o hor√°rio exato) dessa data em que um evento ocorre. O tipo POSIXct foi feito justamente para tratar e lidar com esse tipo de informa√ß√£o.\n\nh <- as.POSIXct(c(\"2020-03-21 15:52:29\", \"2020-03-22 10:30:02\"))\nh\n\n[1] \"2020-03-21 15:52:29 -03\" \"2020-03-22 10:30:02 -03\"\n\n\nPor outro lado, o tipo POSIXlt pode ser especialmente √∫til quando desejamos extrair os componentes de uma vari√°vel de tempo espec√≠fica. Por exemplo, podemos estar interessados apenas no dia do m√™s presente em cada valor, ou ainda, na hora do dia guardada em cada um desses valores. Tal ponto est√° demonstrado no exemplo abaixo:\n\nhl <- as.POSIXlt(c(\"2020-03-21 15:52:29\", \"2020-03-22 10:30:02\"))\n\n## O dia de cada data:\nhl$mday\n\n[1] 21 22\n\n## A hora do dia de cada data:\nhl$hour\n\n[1] 15 10"
  },
  {
    "objectID": "posts/2022/2022-04-06-3nd-edition-rbook/pt/index.html",
    "href": "posts/2022/2022-04-06-3nd-edition-rbook/pt/index.html",
    "title": "Novidades da 3¬∞ edi√ß√£o de Introdu√ß√£o √† Linguagem R: seus fundamentos e sua pr√°tica",
    "section": "",
    "text": "Introdu√ß√£o\n√â com muito prazer que venho compartilhar com voc√™ as novidades que estou trazendo para essa nova edi√ß√£o do livro Introdu√ß√£o √† Linguagem R: seus fundamentos e sua pr√°tica. O lan√ßamento desta nova edi√ß√£o deve ocorrer ainda no meio de Abril de 2022 üìÜ, portanto, fique atento üòâ.\n\n\nO que temos de novo?\nTemos seis novos cap√≠tulos ü§Ø, os quais comp√µe uma nova parte do livro e, trazem consigo, grandes avan√ßos sobre o processo de desenvolvimento de programas no R. Al√©m disso, v√°rias melhorias foram feitas em se√ß√µes espec√≠ficas do livro, especialmente sobre o cap√≠tulo 2.\nPrimeiro, houve uma reorganiza√ß√£o significativa do livro. Os cap√≠tulos pr√©-existentes foram reorganizados em quatro partes diferentes. J√° a quinta e nova parte (Fun√ß√µes e Loops: construindo os seus pr√≥prios programas e automatizando tarefas) √© composta pelos seis novos cap√≠tulos introduzidos nesta edi√ß√£o.\nSegundo, o cap√≠tulo de Fun√ß√µes e Loops foi completamente reescrito, expandido, e, repartido em dois novos cap√≠tulos ü•≥üéâüéâüéâ. Mais especificamente, os cap√≠tulos 14 (Fun√ß√µes) e 15 (Loops) desta edi√ß√£o.\nTerceiro, o cap√≠tulo 16 desta edi√ß√£o traz uma das novidades programadas desde a segunda edi√ß√£o: um novo (e robusto) cap√≠tulo sobre functional programming. Com essa adi√ß√£o, esta obra se torna uma refer√™ncia mais moderna e, se aproxima dos padr√µes adotados hoje pela comunidade internacional de R üòé.\nQuarto, environments e as regras de scoping da linguagem s√£o dois t√≥picos relativamente avan√ßados, e que costumam causar certa confus√£o em muitos iniciantes. Por isso, um novo cap√≠tulo foi produzido para descrever essas funcionalidades que sustentam partes essenciais da linguagem, assim como de alguns dos pacotes que introduzimos ao longo do livro (e.g.¬†dplyr e ggplot2).\nQuinto, v√°rias adi√ß√µes e melhorias foram feitas no cap√≠tulo 6 (Introdu√ß√£o a base de dados relacionais com dplyr) e, principalmente, no cap√≠tulo 2 (Fundamentos da Linguagem R). Dentre elas, temos: um novo estudo de caso (Importando os dados da PINTEC)Õæ novas se√ß√µes sobre as fun√ß√µes str() e is.*()Õæ melhorias significativas sobre as se√ß√µes de Coer√ß√£o no R e Valores especiais do R.\nSexto, foi introduzido um novo cap√≠tulo que descreve os controles condicionais de fluxo (if else statements e switch()) que a linguagem R oferece.\nS√©timo, um novo e pequeno cap√≠tulo foi adicionado √† segunda parte do livro, com o objetivo de introduzir o universo do tidyverse ao leitor de maneira mais clara e amig√°vel ü•∞.\nOitavo, o ap√™ndice contendo as respostas dos exerc√≠cios foi retirado, com o objetivo de reduzir o n√∫mero de p√°ginas do livro. Consequentemente, as respostas dos exerc√≠cios est√£o sendo disponibilizadas em um PDF separado, o qual pode ser baixado gratuitamente, a partir da p√°gina de publica√ß√£o do livro.\n\n\nSobre onde encontrar o livro\nAssim como ocorreu nas edi√ß√µes anteriores, voc√™ poder√° ler toda a obra de maneira gratuita e aberta atrav√©s de seu website üìñ.\nContudo, diferente das edi√ß√µes anteriores, a vers√£o em PDF da obra n√£o ser√° aberta. Voc√™ poder√° adquirir uma vers√£o em PDF ou f√≠sica do livro atrav√©s da loja da Amazon. Ao comprar essas vers√µes, voc√™ estar√° me ajudando a continuar contribuindo com a nossa comunidade ‚ù§Ô∏è.\n\n\nContribua para a obra ou fa√ßa sugest√µes!\nCaso seja de seu interesse, voc√™ pode contribuir diretamente para a obra, ao postar pull requests dentro de seu reposit√≥rio oficial. Para mais, voc√™ tamb√©m pode fazer sugest√µes ou coment√°rios, ao postar issues neste mesmo reposit√≥rio."
  },
  {
    "objectID": "posts/2022/2022-11-06-figma-pkgv0.1.0/en/index.html",
    "href": "posts/2022/2022-11-06-figma-pkgv0.1.0/en/index.html",
    "title": "Introducing the {figma} R package",
    "section": "",
    "text": "I‚Äôm very happy to announce the realease of figma R package to CRAN! This package provides a R interface (or a web client/wrapper) to the Figma API. Below we have all the important links about this package:\n Official repository  Package website  Page on CRAN\nThis is the first release (or the first version) of the package, and for now, it have all the necessary functionality to get all data from a Figma file, and bring it to your R session. But in the future, the package will include more functionalities and endpoints. Please, if you can, test this package and give feedbacks or report bugs by sending Issues on the official repository."
  },
  {
    "objectID": "posts/2022/2022-11-06-figma-pkgv0.1.0/en/index.html#getting-started",
    "href": "posts/2022/2022-11-06-figma-pkgv0.1.0/en/index.html#getting-started",
    "title": "Introducing the {figma} R package",
    "section": "Getting started",
    "text": "Getting started\nFist of all, you need to install the package on your machine, and to do that, you can use this code:\n\ninstall.packages(\"figma\")\n\nOr, to install the development version directly from GitHub:\n\ndevtools::install_github(\"pedropark99/figma\")\n\nNow, to get the data of a Figma file through the Figma API, you have to collect two key variables about your file and your credentials. They are:\n\nfile_key: The ID (or the ‚Äúkey‚Äù) that identifies your Figma file;\ntoken: Your personal access token from the Figma platform;\n\nTo use specifically the figma::get_figma_page() function, you will need to collect a third information, which is the node_id, or the ID that identifies a canvas/page of your Figma file. I explain, in details, on how to collect these key variables on the main vignette package. For brevity reasons, lets assume in this blog post that you already have collected these variables."
  },
  {
    "objectID": "posts/2022/2022-11-06-figma-pkgv0.1.0/en/index.html#use-get_figma_file-to-get-your-figma-file",
    "href": "posts/2022/2022-11-06-figma-pkgv0.1.0/en/index.html#use-get_figma_file-to-get-your-figma-file",
    "title": "Introducing the {figma} R package",
    "section": "Use get_figma_file() to get your Figma file",
    "text": "Use get_figma_file() to get your Figma file\nNow that you have the key (or ID) that identifies your Figma file, and your personal token that identifies yourself, you can use figma::get_figma_file() to get your Figma file:\n\nlibrary(figma)\nfile_key <- \"hch8YlkIrYbU3raDzjPvCz\"\n# Insert your personal token:\ntoken <- \"Your personal token ...\"\n\n# Returns a `httr::response` object:\nfigma_file <- figma::get_figma_file(\n  file_key, token\n)\n\nThe functions from figma package returns a httr::response object by default. But you can use the .output_format argument to fit the data into a more intuitive data strucuture. For example, a tibble::tibble object:\n\n# Returns a `tibble::tibble` object:\nfigma_file <- figma::get_figma_file(\n  file_key, token,\n  .output_format = \"tibble\"\n)\n\nprint(figma_file)\n\n#> # A tibble: 5 √ó 7\n#>   canvas_id canvas_name canvas_type object_id object_name   objec‚Ä¶¬π object_att‚Ä¶¬≤\n#>   <chr>     <chr>       <chr>       <chr>     <chr>         <chr>   <list>      \n#> 1 0:1       Page 1      CANVAS      1:2       Background    RECTAN‚Ä¶ <named list>\n#> 2 0:1       Page 1      CANVAS      5:2       Paragraph     TEXT    <named list>\n#> 3 0:1       Page 1      CANVAS      5:3       Arrow         VECTOR  <named list>\n#> 4 5:4       Page 2      CANVAS      5:5       BackgroundPa‚Ä¶ RECTAN‚Ä¶ <named list>\n#> 5 5:4       Page 2      CANVAS      5:6       Texto da p√°g‚Ä¶ TEXT    <named list>\n#> # ‚Ä¶ with abbreviated variable names ¬π‚Äãobject_type, ¬≤‚Äãobject_attributes\nEach row in the above data.frame is an object drawn in a canvas/page in your Figma file. Every object that you drawn in the canvas of your Figma file, can have a different type (like RECTANGLE, CIRCLE, TEXT, etc.). And objects of different types usually have different attributes.\nFor example, TEXT objects have a characters attribute, which have the exact text that is written in the text box. In the other hand, RECTANGLE objects does not have such attribute.\nAll the attributes of each object are in the ‚Äãobject_attributes column, which is a <list> column. Each row (or, if you prefer, each element) in this column is a list with all the attributes of the object described in the corresponding row. For example, to collect the characters attribute of the first TEXT object described in figma_file (which is in the 2nd row), you could do this:\n\nfigma_file$object_attributes[[2]][[\"characters\"]]\n\n[1] \"Um texto qualquer, que n√£o sei se vai dar certo\"\nOr, you could the functions from dplyr and purrr packages to extract the characters attribute from all TEXT objects of your Figma file, like this:\n\ntext_objects <- figma_file |> \n  dplyr::filter(object_type == 'TEXT') \n\ntext_objects[['object_attributes']] |> \n  purrr::map_chr('characters')\n\n[1] \"Um texto qualquer, que n√£o sei se vai dar certo\" \"Texto da p√°gina 2\""
  },
  {
    "objectID": "posts/2022/2022-12-14-power-bi-memory-error/pt/index.html",
    "href": "posts/2022/2022-12-14-power-bi-memory-error/pt/index.html",
    "title": "Erro de mem√≥ria no Power BI Online? Hora de repensar o seu dashboard",
    "section": "",
    "text": "Em um dia recente, eu descobri que um dos dashboards que estavam publicados em nosso ambiente de produ√ß√£o do Power BI Online havia sofrido um erro de atualiza√ß√£o. Logo, eu prontamente parei o que estava fazendo e comecei a investigar o motivo do erro, at√© porque: 1) o nosso cliente depende dos dados desse dashboard ; e 2) erros em produ√ß√£o n√£o s√£o legais!\nNesse post, eu quero mostrar como esse tipo de erro de atualiza√ß√£o pode ser um forte sinal de que voc√™ precisa repensar o design de seu dashboard. Em outras palavras, meu objetivo √© mostrar que se voc√™ est√° puxando milh√µes e milh√µes de linhas de dados para um dashboard‚Ä¶ √© prov√°vel que voc√™ n√£o tenha entendido o que √© um dashboard e qual o seu prop√≥sito."
  },
  {
    "objectID": "posts/2022/2022-12-14-power-bi-memory-error/pt/index.html#hora-de-explorar-o-terreno-desconhecido",
    "href": "posts/2022/2022-12-14-power-bi-memory-error/pt/index.html#hora-de-explorar-o-terreno-desconhecido",
    "title": "Erro de mem√≥ria no Power BI Online? Hora de repensar o seu dashboard",
    "section": "Hora de explorar o terreno desconhecido",
    "text": "Hora de explorar o terreno desconhecido\nNesse dia, eu estava em minha primeira semana em uma nova equipe, e, eu n√£o conhecia esse dashboard. Em outras palavras, eu havia herdado esse dashboard, que foi criado pelos analistas anteriores dessa equipe. Logo, eu precisava abrir o .pbix desse dashboard e come√ßar a investigar, tentando descobrir que mist√©rios e perigos est√£o escondidos dentro dele.\nInicialmente, percebi oito tabelas associadas ao dashboard que foram puxadas diretamente dos nossos databases SQL (campanhas, cartoes_selecionados, usuarios_por_dia, formatos, inputs, usuarios_por_mes, perfis e tracks), as quais est√£o expostas na imagem abaixo1. Al√©m delas, temos outras duas tabelas calculadas no pr√≥prio .pbix, atrav√©s de DAX (dCalendario e Medidas).\n\n\n\n\n\nTabelas associadas ao arquivo .pbix\n\n\n\n\nDecidi simplesmente clicar no bot√£o de Atualizar. J√° que o erro ocorreu durante a atualiza√ß√£o, imaginei que seria mais simples descobrir a fonte do problema dessa forma.\nA maioria das tabelas atualizaram rapidamente. Por√©m, a tabela input ainda estava atualizando. Em resumo, essa tabela continha todas as mensagens digitadas por todos os usu√°rios que acessaram o nosso sistema.\nO tempo foi passando, e ap√≥s 3 horas com a atualiza√ß√£o rodando em meu computador, o Power BI j√° havia puxado mais de 80 milh√µes de linhas para essa √∫nica tabela. Decidi verificar se o recurso de Atualiza√ß√£o incremental estava ligado para essa tabela input, e, percebi que ele estava desligado."
  },
  {
    "objectID": "posts/2022/2022-12-14-power-bi-memory-error/pt/index.html#a-fonte-do-problema",
    "href": "posts/2022/2022-12-14-power-bi-memory-error/pt/index.html#a-fonte-do-problema",
    "title": "Erro de mem√≥ria no Power BI Online? Hora de repensar o seu dashboard",
    "section": "A fonte do problema",
    "text": "A fonte do problema\nPortanto, a fonte do problema estava claro. Como o recurso de ‚ÄúAtualiza√ß√£o incremental‚Äù estava desligado para essa tabela input, a cada atualiza√ß√£o, o Power BI Online estava recalculando toda a tabela input de uma vez s√≥.\nIsso significa que, todos os dias, o Power BI estava coletando todas as 80 milh√µes de linhas dessa tabela input. Devido a este volume monumental de dados, o servi√ßo do Power BI decidiu interromper a atualiza√ß√£o."
  },
  {
    "objectID": "posts/2022/2022-12-14-power-bi-memory-error/pt/index.html#manuten√ß√£o-se-torna-um-peso-grande",
    "href": "posts/2022/2022-12-14-power-bi-memory-error/pt/index.html#manuten√ß√£o-se-torna-um-peso-grande",
    "title": "Erro de mem√≥ria no Power BI Online? Hora de repensar o seu dashboard",
    "section": "Manuten√ß√£o se torna um peso grande",
    "text": "Manuten√ß√£o se torna um peso grande\nAtualizar 80 milh√µes de linhas n√£o √© pr√°tico, n√£o √© r√°pido, e √© dif√≠cil de manter e testar. Se por algum motivo, voc√™ precisar atualizar todos os dados de seu dashboard2, voc√™ vai muito provavelmente perder uma tarde, talvez um dia inteiro de trabalho s√≥ para completar a atualiza√ß√£o.\n\nInsight 2: Um dashboard deve ser f√°cil de se manter e expandir. Em contrapartida, manter um volume grande de dados em um dashboard √© trabalhoso demais."
  },
  {
    "objectID": "posts/2022/2022-12-14-power-bi-memory-error/pt/index.html#vamos-pensar-um-pouco-sobre-user-experience",
    "href": "posts/2022/2022-12-14-power-bi-memory-error/pt/index.html#vamos-pensar-um-pouco-sobre-user-experience",
    "title": "Erro de mem√≥ria no Power BI Online? Hora de repensar o seu dashboard",
    "section": "Vamos pensar um pouco sobre user experience",
    "text": "Vamos pensar um pouco sobre user experience\nPor um momento, vamos adotar o papel de um UX, e refletir sobre a experi√™ncia dos usu√°rios que consomem o nosso dashboard. √â esquisito pensar dessa forma, entretanto, √†s vezes, n√≥s nos esquecemos que pessoas de verdade usam o nosso produto (nesse caso, o dashboard) e se baseiam nele diariamente para desempenhar trabalhos e planejamentos importantes. Portanto, √© muito importante que eles tenham uma experi√™ncia agrad√°vel utilizando o nosso dashboard.\n\nDefinindo o p√∫blico-alvo: Primeiro, quem utiliza o nosso dashboard?\n\nNa maioria das vezes, quem est√° consumindo os nossos dashboards s√£o gerentes de alguma √°rea. Gente importante, que tem pouco tempo no dia, e que lidam com v√°rias tarefas e responsabilidades ao mesmo tempo.\n√â justamente por essa escassez de tempo e aten√ß√£o que, em geral, gerentes gostam muito de dashboards. Eles gostam de entrar num dashboard, e rapidamente visualizar todos os indicadores que eles precisam acompanhar. Com isso, eles n√£o precisam gastar horas e horas ca√ßando n√∫meros em diferentes lugares, e com diferentes pessoas. Est√° tudo concentrado em um lugar √∫nico e de f√°cil acesso.\nPor isso, um dashboard tem que ser r√°pido. Todo gerente tem pressa, ent√£o, a p√°gina inicial do dashboard precisa carregar r√°pido! Navegar pelas diferentes p√°ginas e vis√µes do dashboard tamb√©m precisa ser uma experi√™ncia r√°pida e fl√∫ida. Ningu√©m gosta de uma p√°gina que demora 5 minutos para carregar‚Ä¶ muito menos um gerente.\n√â por esse mesmo motivo, que cada p√°gina de um dashboard precisa ser focada em um tema central, e manter o m√≠nimo poss√≠vel de informa√ß√£o que o gerente precisa, da forma mais clara poss√≠vel. Se uma mesma p√°gina mistura diferentes temas, o leitor pode ter dificuldade em navegar pelos indicadores e encontrar o que ele est√° procurando (ou seja, misturar temas = confus√£o mental!).\n\nAh! Achei a p√°gina com os indicadores de vendas. Ok. Espera! Por que os indicadores de atendimento est√£o nessa p√°gina? Onde est√° o n√∫mero de vendas de maquininhas nesse m√™s? Ahhh achei! N√£o, espera‚Ä¶ Esse √© o n√∫mero de maquininhas vendidas somente no setor de atendimento, mas eu quero os n√∫meros de venda em TODOS os setores‚Ä¶\n\nPortanto, dashboards precisam ser r√°pidos, claros e bem dividos! E se voc√™ est√° puxando um volume muito grande de dados para dentro dele, voc√™ com certeza vai impactar negativamente a rapidez desse dashboard, pois ele precisa carregar o grande conjunto de dados que voc√™ inseriu l√° dentro. Al√©m disso, um grande volume de dados pode indicar que voc√™ est√° preenchendo esse dashboard com informa√ß√µes que s√£o irrelevante para o gerente.\n\nInsight 3: Dashboards precisam ser r√°pidos, claros e bem dividos!"
  },
  {
    "objectID": "posts/2022/2022-12-14-power-bi-memory-error/pt/index.html#gerentes-querem-indicadores-e-agregados-n√£o-dados-brutos",
    "href": "posts/2022/2022-12-14-power-bi-memory-error/pt/index.html#gerentes-querem-indicadores-e-agregados-n√£o-dados-brutos",
    "title": "Erro de mem√≥ria no Power BI Online? Hora de repensar o seu dashboard",
    "section": "Gerentes querem indicadores e agregados! N√£o dados brutos‚Ä¶",
    "text": "Gerentes querem indicadores e agregados! N√£o dados brutos‚Ä¶\nGerentes querem acompanhar indicadores e agregados que descrevam de maneira r√°pida a situa√ß√£o atual do neg√≥cio que eles gerem, e das pessoas que est√£o envolvidas nele.\nLogo, por que trazer dados brutos para o dashboard? Por que trazer para o dashboard uma tabela com a lista completa de todos os usu√°rios que visitaram o nosso servi√ßo em todos os dias do ano? Se eu posso simplesmente trazer uma tabela j√° agregada, com o n√∫mero de usu√°rios que visitaram esse servi√ßo dentro de cada dia do ano?\n\nInsight 4: Gerentes est√£o interessados em acompanhar indicadores e agregados, ao inv√©s de dados brutos. Portanto, importe os seus dados j√° agregados para dentro do dashboard."
  },
  {
    "objectID": "posts/2022/2022-12-14-power-bi-memory-error/pt/index.html#isso-significa-que-dados-brutos-geralmente-n√£o-devem-estar-em-um-dashboard",
    "href": "posts/2022/2022-12-14-power-bi-memory-error/pt/index.html#isso-significa-que-dados-brutos-geralmente-n√£o-devem-estar-em-um-dashboard",
    "title": "Erro de mem√≥ria no Power BI Online? Hora de repensar o seu dashboard",
    "section": "Isso significa que dados brutos geralmente n√£o devem estar em um dashboard",
    "text": "Isso significa que dados brutos geralmente n√£o devem estar em um dashboard\nIsso tudo n√£o significa que gerentes n√£o consomem dados brutos em momento algum. Mas isso significa que um dashboard √© geralmente o lugar errado para esses dados brutos.\n√â at√© comum em certos momentos um gerente pedir para n√≥s coletarmos um conjunto espec√≠fico de dados brutos para ele. Mas se voc√™ refletir sobre todas as ocasi√µes onde isso ocorreu, voc√™ talvez consiga perceber que essas situa√ß√µes caem em duas categorias:\n\no gerente queria investigar um problema bem espec√≠fico, e √© bem prov√°vel que esse problema n√£o se repita, logo, ele nunca mais vai precisar desses dados brutos espec√≠ficos novamente (i.e.¬†foi uma entrega pontual);\no gerente precisa desses dados brutos com certa frequ√™ncia para alimentar algum fluxo de trabalho que voc√™ n√£o conhece, ou est√° em uma equipe/setor diferente do seu;\n\nEssas duas categorias n√£o justificam incluir dados brutos em um dashboard. Para a primeira situa√ß√£o, voc√™ pode armazenar a query (ou o script) que voc√™ usou no momento para puxar os dados brutos que o gerente te pediu naquele momento. Desse modo, se l√° na frente, por algum motivo voc√™ precisar extrair novamente esses dados brutos, voc√™ precisa apenas retornar √† query e execut√°-la novamente. Al√©m disso, √© muito mais econ√¥mico armazenar centenas de queries distintas, do que armazenar os dados brutos produzidos em cada uma dessas queries (imagine ter centenas de CSV‚Äôs de v√°rios MB‚Äôs armazenados no seu computador‚Ä¶).\nEm minha equipe de trabalho, n√≥s utilizamos um board de cards no estilo kanban (como o Asana, ou o Azure DevOps, etc.) para organizar as nossas tarefas e demandas. Eu particularmente gosto de sempre salvar a query que eu utilizei para completar uma demanda, dentro do card correspondente a essa demanda. Sendo assim, caso eu precisar utilizar essa mesma query, eu procuro rapidamente pelo card dessa demanda no hist√≥rico do nosso board de cards, e, copio a query que est√° salva l√° dentro desse card.\nJ√° na segunda situa√ß√£o, faz mais sentido criar rotinas automatizadas de envio desses dados para o gerente, ou para qualquer que seja a pessoa que esteja precisando desses dados. Ou seja, se por exemplo, o Paulo precisa extrair toda semana, uma lista com todos os usu√°rios que s√£o eleg√≠veis a adquirir um empr√©stimo, eu posso, por exemplo, criar uma rotina automatizada em Python ou em R, que pega os dados brutos do nosso database SQL, filtra todos esses usu√°rios eleg√≠veis, e compila esses dados em um formato agrad√°vel e intuitivo, e por fim, envia esses dados para o Paulo, seja por email, ou talvez, para um servidor ou uma pasta na nuvem que o Paulo tem acesso."
  },
  {
    "objectID": "posts/2022/2022-12-14-power-bi-memory-error/pt/index.html#dashboards-s√£o-ferramentas-de-uso-di√°rio",
    "href": "posts/2022/2022-12-14-power-bi-memory-error/pt/index.html#dashboards-s√£o-ferramentas-de-uso-di√°rio",
    "title": "Erro de mem√≥ria no Power BI Online? Hora de repensar o seu dashboard",
    "section": "Dashboards s√£o ferramentas de uso di√°rio",
    "text": "Dashboards s√£o ferramentas de uso di√°rio\nO gerente depende desse dashboard todos os dias (ou talvez toda semana) para extrair informa√ß√µes importantes sobre o seu neg√≥cio. Portanto, dashboards possuem uma frequ√™ncia de uso alta, e por essa caracter√≠stica, √© essencial que um dashboard seja est√°vel e que esteja sempre o mais atualizado poss√≠vel.\nContudo, ao puxar milh√µes e milh√µes de linhas de dados para um dashboard, todos os dias, voc√™ est√° aumentando as chances desse dashboard enfrentar um erro de atualiza√ß√£o. Isso n√£o √© algo est√°vel!\nVoc√™ n√£o quer erros acontecendo no seu dashboard, pois voc√™ n√£o quer perder uma tarde inteira de trabalho investigando onde nas milh√µes e milh√µes de linhas que voc√™ puxou est√° a fonte do erro. Voc√™ tamb√©m n√£o quer perder horas e horas atualizando essas milh√µes de linhas. Isso est√° bastante relacionado tamb√©m com o insight 2, onde definimos que um dashboard deve ser f√°cil de se manter e expandir.\n\nInsight 5: Dashboards precisam ser est√°veis! Quanto menos erros ele gerar, melhor para voc√™ (que vai gastar menos tempo de debugging e manuten√ß√£o) e tamb√©m para o gerente que utiliza esse dash.\n\nVoc√™ quer um dashboard simples, leve, claro, e que funcione da forma como voc√™ esperava que ele funcionasse. Na empresa onde trabalho, temos um lema: ‚ÄúA simplicidade √© o mais alto n√≠vel de sofistica√ß√£o‚Äù. Portanto, leve essa simplicidade para os seus dashboards. N√£o tente fazer coisas complexas e confusas, que s√£o dif√≠ceis de se entender e de investigar (ou ‚Äúdesbugar‚Äù)."
  },
  {
    "objectID": "posts/2022/2022-12-14-power-bi-memory-error/pt/index.html#as-vezes-n√£o-existe-maneira-simples-de-contornar-o-problema",
    "href": "posts/2022/2022-12-14-power-bi-memory-error/pt/index.html#as-vezes-n√£o-existe-maneira-simples-de-contornar-o-problema",
    "title": "Erro de mem√≥ria no Power BI Online? Hora de repensar o seu dashboard",
    "section": "As vezes n√£o existe maneira simples de contornar o problema",
    "text": "As vezes n√£o existe maneira simples de contornar o problema\nEm certas ocasi√µes, os usu√°rios de um dashboard realmente precisam ver algum tipo de dado bruto dentro dele. Nesses casos, voc√™ tra√ßar algumas outras estrat√©gias e perguntas para reduzir ao m√°ximo o n√∫mero de linhas importadas. Por exemplo:\n\neu posso trazer para dentro dashboard uma parte bastante filtrada dos dados brutos?\n\nOu seja, ao inv√©s de trazer as 80 milh√µes de linhas, ser√° que eu consigo aplicar v√°rios filtros sobre esses dados brutos, antes de import√°-los para dentro do dashboard? Esses filtros podem te ajudar a reduzir drasticamente o n√∫mero de linhas carregadas.\n\nao inv√©s de trazer todos os dados, por que n√£o trazer uma amostra aleat√≥ria da popula√ß√£o?\n\n√â √∫til entender o porqu√™ exatamente o seu usu√°rio precisa ver algum dado bruto em seu dashboard. Ao entender o que esse usu√°rio est√° perseguindo, voc√™ talvez chegue a conclus√£o de que o seu usu√°rio j√° ficaria satisfeito ao ver pelo menos uma parte dos dados brutos (n√£o precisa trazer literalmente tudo). Portanto, voc√™ poderia selecionar uma amostra aleat√≥ria dos dados, e importar apenas essa amostra para dentro do dashboard.\n\nser√° que eu preciso manter o hist√≥rico desses dados brutos dentro do dash?\n\nSer√° que o seu cliente precisa frequentemente visualizar os dados brutos de 6 meses atr√°s? √â muito prov√°vel que n√£o. Ent√£o, por que n√£o manter apenas os dados brutos dos √∫ltimos 30 dias? Em outras palavras, os dados hist√≥ricos s√£o sempre limpos, e apenas os dados brutos mais recentes s√£o mantidos.\nAo reduzir o volume de dados mantidos dentro do dashboard, voc√™ talvez traga uma melhoria consider√°vel sobre o tempo de navega√ß√£o e carregamento do dashboard (lembre-se, um dashboard preciso ser r√°pido, claro e bem divido)."
  },
  {
    "objectID": "posts/2022/2022-12-21-spark-map-v0.2.3/en/index.html",
    "href": "posts/2022/2022-12-21-spark-map-v0.2.3/en/index.html",
    "title": "Introducing the {spark_map} Python package",
    "section": "",
    "text": "spark_map is a python package that offers some tools that help you to apply a function over multiple columns of Apache Spark DataFrames, using pyspark. The package offers two main functions (or ‚Äútwo main methods‚Äù) to distribute your calculations, which are spark_map() and spark_across(). Furthermore, the package offers several methods to map (or select) the columns to which you want to apply your calculations (these methods are called mapping methods in the package).\n Official repository  Package website  Page on PyPI"
  },
  {
    "objectID": "posts/2022/2022-12-21-spark-map-v0.2.3/en/index.html#how-to-install-it",
    "href": "posts/2022/2022-12-21-spark-map-v0.2.3/en/index.html#how-to-install-it",
    "title": "Introducing the {spark_map} Python package",
    "section": "How to install it ?",
    "text": "How to install it ?\nYou can install the package through PyPI, by using the pip tool on your terminal, like this:\npip install spark-map"
  },
  {
    "objectID": "posts/2022/2022-12-21-spark-map-v0.2.3/en/index.html#what-problem-spark_map-solves",
    "href": "posts/2022/2022-12-21-spark-map-v0.2.3/en/index.html#what-problem-spark_map-solves",
    "title": "Introducing the {spark_map} Python package",
    "section": "What problem spark_map solves?",
    "text": "What problem spark_map solves?\nI work a lot with data pipelines using Apache Spark and pyspark at Take Blip. Some day, I got myself writing a very long agg() statement to aggregate multiple columns of my Spark DataFrame with the same function, like this one below:\n\nfrom pyspark.sql.functions import sum, column\naggregates = (\n    spark.table('cards.detailed_sales_per_user')\n        .groupBy('day')\n        .agg(\n            sum(column('cards_lite')).alias('cards_lite'),\n            sum(column('cards_silver')).alias('cards_silver'),\n            sum(column('cards_gold')).alias('cards_gold'),\n            sum(column('cards_premium')).alias('cards_premium'),\n            sum(column('cards_enterprise')).alias('cards_enterprise'),\n            sum(column('cards_business')).alias('cards_business')\n        )\n)\n\nLooking at this code, I had the following thought: ‚Äúthis is not elegant, and is error-prone, because it involves copy and paste, and very subtle changes in each line‚Äù. Following the golden rule of DRY (do not repeat yourself), I had to find a better way to write this code.\nI just wanted to apply the sum() function over multiple columns of cards.detailed_sales_per_user grouped by day. Because of that, I decided to develop the spark_map package, which allows you to declare this operation in a much better, elegant and concise way, by using the spark_map() function.\n\nfrom spark_map.functions import spark_map\nfrom spark_map.mapping import starts_with\ngrouped_by_day = spark.table('cards.detailed_sales_per_user')\\\n    .groupBy('day')\n\naggregates = spark_map(grouped_by_day, starts_with('cards'), sum)"
  },
  {
    "objectID": "posts/2022/2022-12-21-spark-map-v0.2.3/en/index.html#how-spark_map-works",
    "href": "posts/2022/2022-12-21-spark-map-v0.2.3/en/index.html#how-spark_map-works",
    "title": "Introducing the {spark_map} Python package",
    "section": "How spark_map() works ?",
    "text": "How spark_map() works ?\nThe spark_map() function receives three inputs, which are table (i.e.¬†the Spark DataFrame you want to use), mapping (i.e.¬†a ‚Äúmapping‚Äù that describes which columns you want to apply your function), and function (i.e.¬†the function you want to apply to each column in the Spark DataFrame).\nIn short, the starts_with('cards') section tells spark_map() that you want to apply the input function on all columns of grouped_by_day whose name starts with the text 'cards'. In other words, all spark_map() does is to apply the function you want (in the above example this function is sum()) to whatever column it finds in the input DataFrame which fits in the description of your mapping method.\nYou can use different mapping methods to select the columns of your DataFrame, and the package offers several built-in methods which can be very useful for you, which are available through the spark_map.mapping module of the package. You can select columns based on:\n\nat_position(): their position (i.e.¬†3rd, 4th and 5th columns);\nmatches(): a regex to which their match;\nare_of_type(): the type of data their store (i.e.¬†all columns of type int);\nstarts_with() and ends_with(): its name starting or ending with a particular pattern;\nall_of(): its name being inside a specific list of options;"
  },
  {
    "objectID": "posts/2022/2022-12-21-spark-map-v0.2.3/en/index.html#the-differences-between-spark_map-and-spark_across",
    "href": "posts/2022/2022-12-21-spark-map-v0.2.3/en/index.html#the-differences-between-spark_map-and-spark_across",
    "title": "Introducing the {spark_map} Python package",
    "section": "The differences between spark_map() and spark_across()",
    "text": "The differences between spark_map() and spark_across()\nThere are two main functions in the package that performs the heavy work, which are spark_map() and spark_across().\nBoth of these functions perform the same work, which is to apply a function over a set of columns of a Spark DataFrame. But they differ in the method they use to apply this function. While spark_map() uses the agg() method of Spark DataFrame‚Äôs to apply the function, spark_across() uses the withColumn() method to do so.\nThis means that you will mainly use spark_map() when you want to calculate aggregates. Is worthy pointing out that spark_map() works perfectly with grouped DataFrames as well (i.e.¬†GroupedData). In the other hand, you will use spark_across() when you want to just transform the values of multiple colums at once by applying the same function over them."
  },
  {
    "objectID": "posts/2022/2022-12-26-4th-edition-rbook/pt/index.html",
    "href": "posts/2022/2022-12-26-4th-edition-rbook/pt/index.html",
    "title": "Novidades da 4¬∞ edi√ß√£o de Introdu√ß√£o √† Linguagem R: seus fundamentos e sua pr√°tica",
    "section": "",
    "text": "Introdu√ß√£o\n√â com muito prazer que venho compartilhar com voc√™ as novidades que estou trazendo para essa nova edi√ß√£o do livro Introdu√ß√£o √† Linguagem R: seus fundamentos e sua pr√°tica. Esta quarta edi√ß√£o busca principalmente fazer algumas corre√ß√µes e adi√ß√µes que buscam manter o livro como um refer√™ncia moderna, introdut√≥ria e t√©cnica sobre a linguagem R.\n Compre uma vers√£o do livro  P√°gina de publica√ß√£o  Leia online\n\n\nO que temos de novo?\nPrimeiro, a se√ß√£o do cap√≠tulo 4 que citava o pacote SAScii foi removida. Pois durante o desenvolvimento desta quarta edi√ß√£o, foi identificado que este pacote n√£o estava funcionando corretamente em vers√µes mais recentes do R.\nSegundo, uma nova se√ß√£o foi adicionada ao cap√≠tulo 5, para introduzir o novo operador pipe do R (|>) - que est√° dispon√≠vel desde a vers√£o 4.1 da linguagem, al√©m de explicar as diferen√ßas deste novo operador com o operador pipe do pacote magrittr.\nTerceiro, v√°rias melhorias e pequenas corre√ß√µes foram aplicadas sobre o cap√≠tulo 8, com o objetivo de melhorar a clareza do conhecimento exposto e da organiza√ß√£o do cap√≠tulo.\nQuarto, a se√ß√£o Alterando as fontes do seu gr√°fico no cap√≠tulo 9 foi reformulada, com o objetivo de substituir o pacote extrafont (o qual era a solu√ß√£o descrita em edi√ß√µes passadas desta obra) pelo pacote ragg, o qual se tornou uma solu√ß√£o mais moderna e robusta para o uso de fontes em gr√°ficos do R.\nQuinto, tivemos algumas melhorias sobre o cap√≠tulo 4, especialmente sobre a descri√ß√£o de endere√ßos absolutos e relativos, assim como a se√ß√£o A fun√ß√£o guess_encoding() como um poss√≠vel guia que foi atualizada com o objetivo de acompanhar as mudan√ßas recentes sobre a fun√ß√£o readr::guess_encoding().\n\n\nSobre onde encontrar o livro\nVoc√™ pode ler toda a obra de maneira gratuita e aberta atrav√©s de seu website üìñ. Caso voc√™ queira contribuir para o projeto desse livro, voc√™ pode adquirir uma vers√£o f√≠sica ou em EBook do livro atrav√©s da loja da Amazon. Ao comprar essas vers√µes, voc√™ estar√° me ajudando a continuar contribuindo com a nossa comunidade ‚ù§Ô∏è. Al√©m disso, voc√™ tamb√©m pode doar um Pix para o autor (veja a p√°gina Donate or Sponsor Me).\n\n\nContribua para a obra ou fa√ßa sugest√µes!\nCaso seja de seu interesse, voc√™ pode contribuir diretamente para a obra, ao postar pull requests dentro de seu reposit√≥rio oficial. Para mais, voc√™ tamb√©m pode fazer sugest√µes ou coment√°rios, ao postar issues neste mesmo reposit√≥rio."
  },
  {
    "objectID": "posts/2023/2023-01-10-join-duplicates/pt/index.html",
    "href": "posts/2023/2023-01-10-join-duplicates/pt/index.html",
    "title": "JOINs s√£o importantes fontes de duplica√ß√µes em seus dados",
    "section": "",
    "text": "Quando estamos construindo uma nova tabela de dados, √© muito comum compararmos os nossos resultados com tabelas anteriores e nos depararmos com problemas de diverg√™ncia nos dados. Isto √©, situa√ß√µes como:\n\nUhmm‚Ä¶ a tabela antiga indica que o n√∫mero de maquininhas vendidas no m√™s de Dezembro foi de 1387. Por√©m, esse mesmo indicador na tabela nova est√° em 1824 para o mesmo m√™s de Dezembro. Porque esse aumento?\n\nAumentos desse tipo podem ocorrer por uma variedade de raz√µes. Por√©m, opera√ß√µes de JOIN tem sido uma raz√£o espec√≠fica que tenho enfrentado com muita frequ√™ncia em meu trabalho. Em outras palavras, JOINs s√£o fontes extremamente comuns de dados duplicados. Como resultado, esses dados duplicados acabam gerando um ‚Äúefeito expansivo‚Äù sobre os seus indicadores e suas tabelas.\nMuitos analistas n√£o compreendem o porqu√™, ou n√£o enxergam como isso pode ocorrer. Nesse post, busco justamente esclarecer como uma opera√ß√£o de JOIN pode causar esse ‚Äúefeito expansivo‚Äù em seus dados. Eu tamb√©m explico esse efeito em detalhes no cap√≠tulo 6 do meu livro introdut√≥rio da linguagem R. Mais especificamente, a partir da se√ß√£o Rela√ß√µes entre keys: primary keys s√£o menos comuns do que voc√™ pensa. Portanto, grande parte do conhecimento exposto aqui s√£o refer√™ncias diretas ao livro."
  },
  {
    "objectID": "posts/2023/2023-01-10-join-duplicates/pt/index.html#necessidade-inicial",
    "href": "posts/2023/2023-01-10-join-duplicates/pt/index.html#necessidade-inicial",
    "title": "JOINs s√£o importantes fontes de duplica√ß√µes em seus dados",
    "section": "Necessidade inicial",
    "text": "Necessidade inicial\nVamos supor que, no in√≠cio, voc√™ precisava manter um indicador de ‚Äún√∫mero de usu√°rios por cor de pele‚Äù em um relat√≥rio. Para isso, voc√™ simplesmente contava o n√∫mero de linhas na tabela cores_de_pele agrupado pelos valores da coluna Cor. Como demonstrado abaixo:\n\nlibrary(dplyr)\nusuarios_por_cor <- cores_de_pele |>\n    group_by(Cor) |>\n    summarise(N_usuarios = n())\n\nusuarios_por_cor\n\n# A tibble: 3 √ó 2\n  Cor     N_usuarios\n  <chr>        <int>\n1 Amarelo          1\n2 Branco           2\n3 Pardo            1"
  },
  {
    "objectID": "posts/2023/2023-01-10-join-duplicates/pt/index.html#uma-nova-necessidade",
    "href": "posts/2023/2023-01-10-join-duplicates/pt/index.html#uma-nova-necessidade",
    "title": "JOINs s√£o importantes fontes de duplica√ß√µes em seus dados",
    "section": "Uma nova necessidade",
    "text": "Uma nova necessidade\nPor√©m, uma nova necessidade surge no time. Agora, voc√™ precisa calcular tamb√©m a ‚Äúaltura m√©dia por cor de pele‚Äù. Voc√™ sabe que as alturas dos usu√°rios est√£o armazenadas na tabela alturas, contudo, voc√™ precisa trazer essas alturas para dentro da tabela cores_de_pele, para que voc√™ possa de fato calcular a altura m√©dia para cada cor de pele.\nPortanto, voc√™ precisa realizar um JOIN entre essas tabelas, e √© isso que estamos fazendo no c√≥digo abaixo:\n\ndados <- cores_de_pele |>\n    left_join(alturas, by = \"ID\")\n\nAgora, temos uma nova tabela chamada dados que cont√©m todos os dados que precisamos para calcular ambos os indicadores (‚Äún√∫mero de usu√°rios‚Äù e ‚Äúaltura m√©dia‚Äù) para cada cor de pele. Entretanto, quando calculamos esses indicadores com essa tabela dados, perceba que o n√∫mero de usu√°rios (indicador N_usuarios) de cor ‚ÄúAmarelo‚Äù sofreu um aumento repentino.\n\nindicadores <- dados |>\n    group_by(Cor) |>\n    summarise(\n        N_usuarios = n(),\n        Altura_media = mean(Altura, na.rm = TRUE)\n    )\n\nindicadores\n\n# A tibble: 3 √ó 3\n  Cor     N_usuarios Altura_media\n  <chr>        <int>        <dbl>\n1 Amarelo          3         1.74\n2 Branco           2         1.58\n3 Pardo            1       NaN   \n\n\nRepare que n√≥s n√£o mudamos a f√≥rmula de c√°lculo do indicador N_usuarios. N√≥s aplicamos a mesma fun√ß√£o n() que utilizamos anteriormente. N√≥s tamb√©m agrupamos a tabela dados pela coluna Cor com group_by(), da mesma forma que fizemos anteriormente. Porque esse aumento ocorreu?\nN√≥s n√£o mudamos nada na f√≥rmula de c√°lculo do indicador N_usuarios. Por√©m, n√≥s introduzimos um novo item na cadeia de transforma√ß√µes da tabela. Mais especificamente, um LEFT JOIN realizado pela fun√ß√£o left_join(). Ou seja, o JOIN √© o que mudou nesse c√≥digo, e ele √© o culpado por esse estranho e repentino aumento no n√∫mero de usu√°rios de cor ‚ÄúAmarelo‚Äù."
  },
  {
    "objectID": "posts/2023/2023-01-10-join-duplicates/pt/index.html#o-que-aconteceu",
    "href": "posts/2023/2023-01-10-join-duplicates/pt/index.html#o-que-aconteceu",
    "title": "JOINs s√£o importantes fontes de duplica√ß√µes em seus dados",
    "section": "O que aconteceu?",
    "text": "O que aconteceu?\nSe olharmos bem para a tabela resultado do JOIN (tabela dados) podemos come√ßar a compreender o que aconteceu. Perceba que temos 6 linhas nessa tabela, isto √©, temos 2 linhas a mais que a tabela cores_de_pele (que possui 4 linhas). Perceba tamb√©m que temos 3 linhas nessa tabela descrevendo o mesmo usu√°rio de ID 105. Ou seja, temos dados duplicados para esse usu√°rio.\n\ndados\n\n# A tibble: 6 √ó 4\n     ID Cor     DataRegistro Altura\n  <dbl> <chr>   <date>        <dbl>\n1   100 Pardo   NA            NA   \n2   102 Branco  2022-01-10     1.58\n3   104 Branco  NA            NA   \n4   105 Amarelo 2022-01-10     1.72\n5   105 Amarelo 2022-06-12     1.74\n6   105 Amarelo 2022-08-24     1.75\n\n\nO usu√°rio de ID 105 √© o √∫nico usu√°rio de cor ‚ÄúAmarelo‚Äù na tabela. Portanto, essas 3 linhas referentes ao ID 105 s√£o a causa da mudan√ßa repentina no indicador N_usuarios para a cor ‚ÄúAmarelo‚Äù. Por√©m, como podemos ver abaixo, a tabela cores_de_pele tem 1 √∫nica linha para o usu√°rio de ID 105. Como essa √∫nica linha se transformou em tr√™s?\n\ncores_de_pele\n\n# A tibble: 4 √ó 2\n     ID Cor    \n  <dbl> <chr>  \n1   100 Pardo  \n2   102 Branco \n3   104 Branco \n4   105 Amarelo"
  },
  {
    "objectID": "posts/2023/2023-01-10-join-duplicates/pt/index.html#entenda-o-processo-de-pareamento-de-um-join",
    "href": "posts/2023/2023-01-10-join-duplicates/pt/index.html#entenda-o-processo-de-pareamento-de-um-join",
    "title": "JOINs s√£o importantes fontes de duplica√ß√µes em seus dados",
    "section": "Entenda o processo de pareamento de um JOIN",
    "text": "Entenda o processo de pareamento de um JOIN\nA √∫nica linha de ID 105 na tabela cores_de_pele se transformou em 3 linhas devido ao processo de pareamento dos dados realizado pelo JOIN. Todo JOIN, independe do tipo que ele seja (left, inner, right, full), vai sempre realizar um processo de pareamento entre os dados das duas tabelas, utilizando as colunas que representam as ‚Äúchaves‚Äù do JOIN (Faria 2022).\nPodemos visualizar esse processo de pareamento dos dados em Figure¬†1. Perceba que, tanto no exemplo dessa imagem, quanto no exemplo desse post, as chaves do JOIN s√£o representadas pela coluna ID. Logo, o JOIN vai puxar os dados de uma tabela para a outra, utilizando os valores dessa coluna como guia.\n\n\n\nFigure¬†1: Processo de pareamento realizado em um JOIN\n\n\nNo exemplo de Figure¬†1, ambas as tabelas que est√£o sendo unidas possuem uma linha para cada ID. Ou seja, n√£o existe IDs duplicados em nenhuma das duas tabelas, formando assim, uma rela√ß√£o de ‚Äúum para um‚Äù entre as chaves do JOIN.\nContudo, no exemplo deste post, a tabela alturas possui tr√™s linhas diferentes para o mesmo ID 105, enquanto a tabela cores_de_pele n√£o apresenta IDs duplicados. Isso acaba formando uma rela√ß√£o de ‚Äúum para muitos‚Äù entre as chaves do JOIN. Nesse caso, como o processo de pareamento do JOIN deve se comportar? Bem, o seguinte vai acontecer‚Ä¶\n\nO JOIN vai pegar o ID 105 da tabela cores_de_pele e pesquisar por ele ao longo da tabela alturas. Como resultado, o JOIN vai localizar tr√™s linhas distintas para o ID 105 na tabela alturas.\nO JOIN percebe que h√° um desequil√≠brio (1 linha de cores_de_pele \\(\\times\\) 3 linhas de alturas).\nPara reequilibrar essa balan√ßa, o JOIN vai executar um produto cartesiano entre as linhas dessas duas tabelas.\n\nA Figure¬†2 apresenta de forma visual essa conex√£o:\n\n\n\nFigure¬†2: Uma representa√ß√£o visual do efeito expansivo sobre o ID 105\n\n\nOu seja, o JOIN vai retornar como resultado, todas as combina√ß√µes poss√≠veis entre a linha √∫nica de cores_de_pele e as 3 linhas de alturas. Ou seja, a linha √∫nica de cores_de_pele √© combinada com cada uma das 3 linhas de alturas. Como resultado, temos as 3 linhas de ID 105 na tabela dados:\n\ndados\n\n# A tibble: 6 √ó 4\n     ID Cor     DataRegistro Altura\n  <dbl> <chr>   <date>        <dbl>\n1   100 Pardo   NA            NA   \n2   102 Branco  2022-01-10     1.58\n3   104 Branco  NA            NA   \n4   105 Amarelo 2022-01-10     1.72\n5   105 Amarelo 2022-06-12     1.74\n6   105 Amarelo 2022-08-24     1.75"
  },
  {
    "objectID": "posts/en.html",
    "href": "posts/en.html",
    "title": "Posts in English",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nWhat I learned from my first Python package\n\n\n\n\n\nSharing my mistakes from developing my first Python package published at PyPI\n\n\n\n\n\n\nJan 30, 2023\n\n\nPedro Duarte Faria\n\n\n\n\n\n\n  \n\n\n\n\nIntroducing the {spark_map} Python package\n\n\n\n\n\n\n\nPython\n\n\nPackage\n\n\npyspark\n\n\nApache Spark\n\n\n\n\nWith this package, you can easily apply a function over multiple columns of a Spark DataFrame\n\n\n\n\n\n\nDec 21, 2022\n\n\nPedro Duarte Faria\n\n\n\n\n\n\n  \n\n\n\n\nIntroducing the {figma} R package\n\n\n\n\n\n\n\nR Language\n\n\nPackage\n\n\nFigma\n\n\nAPI\n\n\n\n\nWith this package, you can access the Figma API to bring your design files to R üé®!\n\n\n\n\n\n\nNov 6, 2022\n\n\nPedro Duarte Faria\n\n\n\n\n\n\n  \n\n\n\n\nRecipient table and source table\n\n\nA second view on outer joins\n\n\n\n\nJOINs\n\n\nTeaching\n\n\n\n\nA different (maybe crazy) view on how to teach/explain Outer joins to students\n\n\n\n\n\n\nJan 2, 2021\n\n\nPedro Duarte Faria\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "All Posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nWhat I learned from my first Python package\n\n\nSharing my mistakes from developing my first Python package published at PyPI\n\n\n\nPedro Duarte Faria\n\n\nJan 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJOINs s√£o importantes fontes de duplica√ß√µes em seus dados\n\n\n\nJOINs\n\n\n\nSe os seus dados crescerem de forma repentina, sem explica√ß√£o aparente, verifique se os seus JOINs s√£o a fonte desse problema\n\n\n\nPedro Duarte Faria\n\n\nJan 10, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNovidades da 4¬∞ edi√ß√£o de Introdu√ß√£o √† Linguagem R: seus fundamentos e sua pr√°tica\n\n\n\nBook\n\n\nR Language\n\n\n\nEsta quarta edi√ß√£o traz algumas melhorias que buscam manter um dos principais objetivos deste livro, que √© ser uma refer√™ncia moderna, introdut√≥ria e t√©cnica sobre a‚Ä¶\n\n\n\nPedro Duarte Faria\n\n\nDec 26, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroducing the {spark_map} Python package\n\n\n\nPython\n\n\nPackage\n\n\npyspark\n\n\nApache Spark\n\n\n\nWith this package, you can easily apply a function over multiple columns of a Spark DataFrame\n\n\n\nPedro Duarte Faria\n\n\nDec 21, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nErro de mem√≥ria no Power BI Online? Hora de repensar o seu dashboard\n\n\n\nPower BI\n\n\nPower BI Online\n\n\n\nNeste post explico como um erro de mem√≥ria no Power BI Online pode ser um forte sinal de que voc√™ est√° errando no design de seu dashboard\n\n\n\nPedro Duarte Faria\n\n\nDec 14, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroducing the {figma} R package\n\n\n\nR Language\n\n\nPackage\n\n\nFigma\n\n\nAPI\n\n\n\nWith this package, you can access the Figma API to bring your design files to R üé®!\n\n\n\nPedro Duarte Faria\n\n\nNov 6, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNovidades da 3¬∞ edi√ß√£o de Introdu√ß√£o √† Linguagem R: seus fundamentos e sua pr√°tica\n\n\n\nBook\n\n\nR Language\n\n\n\nUma grande reforma sobre a obra foi feita para esta nova edi√ß√£o. Como resultado, temos seis novos cap√≠tulos para voc√™!\n\n\n\nPedro Duarte Faria\n\n\nApr 6, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNovidades da 2¬∞ edi√ß√£o de Introdu√ß√£o √† Linguagem R: seus fundamentos e sua pr√°tica\n\n\n\nBook\n\n\nR Language\n\n\n\nEsse post descreve as novas adi√ß√µes √† segunda edi√ß√£o do livro Introdu√ß√£o √† Linguagem R: seus fundamentos e sua pr√°tica. Fatores (factors); Datas e vari√°veis de tempo‚Ä¶\n\n\n\nPedro Duarte Faria\n\n\nMay 26, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRecipient table and source table\n\n\n\nJOINs\n\n\nTeaching\n\n\n\nA different (maybe crazy) view on how to teach/explain Outer joins to students\n\n\n\nPedro Duarte Faria\n\n\nJan 2, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTabela destinat√°ria e tabela fonte\n\n\n\nJOINs\n\n\nTeaching\n\n\n\nUm vis√£o diferente (talvez maluca) sobre como ensinar/explicar Outer joins para seus alunos\n\n\n\nPedro Duarte Faria\n\n\nJan 2, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResultados do Formul√°rio de Pesquisa de Interesse - Curso Introdut√≥rio de R\n\n\n\nR Language\n\n\nTeaching\n\n\n\nUma r√°pida an√°lise sobre o impacto e as sugest√µes fornecidas ao Curso Introdut√≥rio de R\n\n\n\nPedro Duarte Faria\n\n\nOct 17, 2020\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/pt.html",
    "href": "posts/pt.html",
    "title": "Posts em Portugu√™s",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nJOINs s√£o importantes fontes de duplica√ß√µes em seus dados\n\n\n\n\n\n\n\nJOINs\n\n\n\n\nSe os seus dados crescerem de forma repentina, sem explica√ß√£o aparente, verifique se os seus JOINs s√£o a fonte desse problema\n\n\n\n\n\n\nJan 10, 2023\n\n\nPedro Duarte Faria\n\n\n\n\n\n\n  \n\n\n\n\nNovidades da 4¬∞ edi√ß√£o de Introdu√ß√£o √† Linguagem R: seus fundamentos e sua pr√°tica\n\n\n\n\n\n\n\nBook\n\n\nR Language\n\n\n\n\nEsta quarta edi√ß√£o traz algumas melhorias que buscam manter um dos principais objetivos deste livro, que √© ser uma refer√™ncia moderna, introdut√≥ria e t√©cnica sobre a Linguagem R.\n\n\n\n\n\n\nDec 26, 2022\n\n\nPedro Duarte Faria\n\n\n\n\n\n\n  \n\n\n\n\nErro de mem√≥ria no Power BI Online? Hora de repensar o seu dashboard\n\n\n\n\n\n\n\nPower BI\n\n\nPower BI Online\n\n\n\n\nNeste post explico como um erro de mem√≥ria no Power BI Online pode ser um forte sinal de que voc√™ est√° errando no design de seu dashboard\n\n\n\n\n\n\nDec 14, 2022\n\n\nPedro Duarte Faria\n\n\n\n\n\n\n  \n\n\n\n\nNovidades da 3¬∞ edi√ß√£o de Introdu√ß√£o √† Linguagem R: seus fundamentos e sua pr√°tica\n\n\n\n\n\n\n\nBook\n\n\nR Language\n\n\n\n\nUma grande reforma sobre a obra foi feita para esta nova edi√ß√£o. Como resultado, temos seis novos cap√≠tulos para voc√™!\n\n\n\n\n\n\nApr 6, 2022\n\n\nPedro Duarte Faria\n\n\n\n\n\n\n  \n\n\n\n\nNovidades da 2¬∞ edi√ß√£o de Introdu√ß√£o √† Linguagem R: seus fundamentos e sua pr√°tica\n\n\n\n\n\n\n\nBook\n\n\nR Language\n\n\n\n\nEsse post descreve as novas adi√ß√µes √† segunda edi√ß√£o do livro Introdu√ß√£o √† Linguagem R: seus fundamentos e sua pr√°tica. Fatores (factors); Datas e vari√°veis de tempo (date, POSIXct); al√©m da introdu√ß√£o de exerc√≠cios em cada cap√≠tulo, est√£o entre as principais novidades da pr√≥xima edi√ß√£o.\n\n\n\n\n\n\nMay 26, 2021\n\n\nPedro Duarte Faria\n\n\n\n\n\n\n  \n\n\n\n\nTabela destinat√°ria e tabela fonte\n\n\nUma segunda vis√£o sobre outer joins\n\n\n\n\nJOINs\n\n\nTeaching\n\n\n\n\nUm vis√£o diferente (talvez maluca) sobre como ensinar/explicar Outer joins para seus alunos\n\n\n\n\n\n\nJan 2, 2021\n\n\nPedro Duarte Faria\n\n\n\n\n\n\n  \n\n\n\n\nResultados do Formul√°rio de Pesquisa de Interesse - Curso Introdut√≥rio de R\n\n\n\n\n\n\n\nR Language\n\n\nTeaching\n\n\n\n\nUma r√°pida an√°lise sobre o impacto e as sugest√µes fornecidas ao Curso Introdut√≥rio de R\n\n\n\n\n\n\nOct 17, 2020\n\n\nPedro Duarte Faria\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "publications/book/introd-pyspark/en/index.html",
    "href": "publications/book/introd-pyspark/en/index.html",
    "title": "Introduction to pyspark",
    "section": "",
    "text": "Still under construction üõ†Ô∏è ‚ö†Ô∏è!\nThis book is still under active construction and development! This means that not all chapters are ready yet, and the current contents might change in the close future. However, you can already read some of its parts by visiting its website.\n\n\nAbout the book\n Official repository  Read online\nIn summary, this book aims to give a solid introduction (for python and not python users) to the pyspark package, and on how to use it to build Spark applications for data pipelines and interactive data analysis.\nAlthough we have a good range of materials about Apache Spark in general, such as Damji et al. (2020) and Chambers and Zaharia (2018), we do not have much abundance of materials about the APIs of Spark in ‚Äúforeign‚Äù languages, like the Python (pyspark) and R (SparkR) APIs.\nThe reason for this is simple: the Spark API have a consistent structure across all languages. As consequence, a general book about Spark can fairly cover all languages at once. In other words, Spark code in Scala can be easily translated into python code with pyspark. Because the structure of the code is very similar between all languages.\nSo why this book? First, python is a more popular and friendly language than Scala or Java. If the reader is not interested in learning Java or Scala, why show Java/Scala code to him? Is very important to focus solely on what interest the reader, specially if it is in a language that he is familiar with. Second, I had some time to spent, and a lot of practical experience with pyspark on production to share (so‚Ä¶ why not write a book about it?).\n\n\nCover\n\n\n\n\n\n\nReferences\n\nChambers, Bill, and Matei Zaharia. 2018. Spark: The Definitive Guide: Big Data Processing Made Simple. Sebastopol, CA: O‚ÄôReilly Media.\n\n\nDamji, Jules, Brooke Wenig, Tathagata Das, and Denny Lee. 2020. Learning Spark: Lightning-Fast Data Analytics. Sebastopol, CA: O‚ÄôReilly Media."
  },
  {
    "objectID": "publications/book/introducao_linguagem_R/pt/index.html",
    "href": "publications/book/introducao_linguagem_R/pt/index.html",
    "title": "Introdu√ß√£o √† Linguagem R: seus fundamentos e sua pr√°tica",
    "section": "",
    "text": "Sobre o livro\n Compre uma vers√£o do livro  Leia online  Respostas dos exerc√≠cios\nEste livro oferece uma descri√ß√£o profunda sobre os fundamentos da linguagem R, e como eles se aplicam no contexto da an√°lise de dados. Sua principal contribui√ß√£o para a literatura brasileira hoje, est√° no combate de dois problemas recorrentes nos materiais dispon√≠veis em portugu√™s sobre a linguagem: 1) a falta de profundidade de muitos materiais, que tentam abordar muitos assuntos em um espa√ßo muito curto; 2) a alta especializa√ß√£o de muitos materiais, que s√£o de dif√≠cil transposi√ß√£o para aplica√ß√µes gerais em an√°lises de dados.\n\n\nO que voc√™ aprende ?\nAtrav√©s deste livro, voc√™ pode aprender sobre os fundamentos da linguagem R, e como eles se aplicam a √°rea de an√°lise de dados. Em mais detalhes:\n\nIntroduzindo a linguagem: aprenda sobre como definir e como trabalhar com objetos; conhe√ßa as estruturas e tipos de dados oferecidos pela linguagem; entenda como os processos de coer√ß√£o e os valores especiais da linguagem podem afetar os seus resultados.\nImporta√ß√£o e transforma√ß√£o: aprenda a importar, transformar e formatar suas tabelas atrav√©s dos pacotes readr, readxl, haven, dplyr e tidyr. Aplicando opera√ß√µes de ordena√ß√£o, filtro, sele√ß√£o e expans√£o, al√©m de opera√ß√µes de piv√¥ e join‚Äôs.\nVisualiza√ß√£o de dados: aprenda a utilizar o pacote ggplot2 para produzir gr√°ficos elegantes e efetivos para apresentar os seus dados e as suas conclus√µes.\nProgramando a sua an√°lise: aprenda a utilizar controles de fluxo, fun√ß√µes e loops para automatizar tarefas e solucionar os seus problemas de maneira simples e clara.\nFunctional programming: aprenda a utilizar o pacote purrr para distribuir rapidamente os seus c√°lculos ao longo de m√∫ltiplos inputs.\nDebugging e environments: conhe√ßa as principais t√©cnicas de debugging existentes na linguagem R, e, aprenda como investigar erros em suas fun√ß√µes. Al√©m disso, entenda como a linguagem procura pelos seus objetos e, como voc√™ pode produzir resultados inesperados durante essa busca.\n\n\n\nCompre uma vers√£o f√≠sica do livro!\nVoc√™ pode adquirir uma vers√£o f√≠sica do livro atrav√©s da loja da Amazon. Uma vers√£o eBook do livro tamb√©m est√° dispon√≠vel. Ao adquirir esses produtos, voc√™ estar√° me ajudando a continuar com esse projeto e a contribuir com nossa comunidade brasileira de R.\n\n\nLeia o livro online\nCaso voc√™ n√£o possa comprar uma vers√£o f√≠sica do livro, voc√™ ainda pode ler gratuitamente a obra completa atrav√©s de seu site.\n\n\nCitando o livro\nArquivo BibTex:\n\n\n@book{pedro2022,\n  title = {Introdu√ß√£o √† Linguagem R},\n  subtitle = {seus fundamentos e sua pr√°tica},\n  author = {Pedro Duarte Faria},\n  year = {2022},\n  edition = {4},\n  address = {Belo Horizonte},\n  month = {Dezembro},\n  isbn = {978-65-00-57872-0},\n  note = {https://pedro-faria.netlify.app/pt/publication/book/introducao_linguagem_r/}\n}\n\n\n\n\nContribua para o projeto\nVoc√™ tamb√©m pode contribuir diretamente para a obra, ao postar pull requests ou issues no reposit√≥rio oficial do livro no GitHub.\n\n\nCapa do livro"
  },
  {
    "objectID": "publications/en.html",
    "href": "publications/en.html",
    "title": "Publications in English",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nIntroduction to pyspark\n\n\n\n\n\n\n\nPython\n\n\nApache Spark\n\n\nBook\n\n\n\n\nThis book offers a introduction on how to build Spark applications using the pyspark python package\n\n\n\n\n\n\nPedro Duarte Faria\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "publications/index.html",
    "href": "publications/index.html",
    "title": "All Publications",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nIntroduction to pyspark\n\n\n\nPython\n\n\nApache Spark\n\n\nBook\n\n\n\nThis book offers a introduction on how to build Spark applications using the pyspark python package\n\n\n\nPedro Duarte Faria\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntrodu√ß√£o √† Linguagem R: seus fundamentos e sua pr√°tica\n\n\n\nR Language\n\n\nBook\n\n\nBrazil\n\n\n\nEste livro oferece uma descri√ß√£o profunda sobre os fundamentos da linguagem R, e como eles se aplicam no contexto da an√°lise de dados.\n\n\n\nPedro Duarte Faria\n\n\nDec 1, 2022\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "publications/pt.html",
    "href": "publications/pt.html",
    "title": "Publica√ß√µes em Portugu√™s",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nIntrodu√ß√£o √† Linguagem R: seus fundamentos e sua pr√°tica\n\n\n\n\n\n\n\nR Language\n\n\nBook\n\n\nBrazil\n\n\n\n\nEste livro oferece uma descri√ß√£o profunda sobre os fundamentos da linguagem R, e como eles se aplicam no contexto da an√°lise de dados.\n\n\n\n\n\n\nDec 1, 2022\n\n\nPedro Duarte Faria\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2023/2023-01-30-python-pckg/en/index.html",
    "href": "posts/2023/2023-01-30-python-pckg/en/index.html",
    "title": "What I learned from developing my first Python package",
    "section": "",
    "text": "In 2022, I developed my first Python package called spark_map, and published it at PyPI. I wrote a post introducing this package, and showing a small use case, if you are interested.\nAlthough spark_map is a small package, I had a hard time developing it. More specifically, the python code was not hard to develop. But packaging it into a proper package was hard. In this post, I want to share a few things that I learned about Python package development in this process."
  },
  {
    "objectID": "posts/2023/2023-01-30-python-pckg/en/index.html#do-not-alter-pythonpath-or-sys.path-variables",
    "href": "posts/2023/2023-01-30-python-pckg/en/index.html#do-not-alter-pythonpath-or-sys.path-variables",
    "title": "What I learned from developing my first Python package",
    "section": "3.2 Do not alter PYTHONPATH or sys.path variables",
    "text": "3.2 Do not alter PYTHONPATH or sys.path variables\nThe sys.path variable is a standard Python list, and, as any other list, can be altered to include other directories that are not currently there. The same goes for the PYTHONPATH variable, which is an environment variable, and can be altered too.\nAs an example, when you try to import your package, which is stored at folder A, and, you face a ModuleNotFoundError error, you might be tempted to alter PYTHONPATH or sys.path, to add the folder A to this search path of Python. DO NOT DO IT! YOU SHOULD NEVER alter PYTHONPATH or sys.path! At least, not inside a Python package.\nIn other words, if at some point inside the source code of your Python package, you execute a code like this:\n\nimport sys\nsys.path.append('./../weird-unknow-folder')\n\njust erase this code! Python packages are made to be used by other peoples, and with a code like this above, you might alter the search path of this user in a very bad way. Altering the search path of the user is just a bad idea. Because you can accidentaly produce a bad and confusing side effect to the user‚Äôs session, which can be hard to debug and solve.\nBesides, in the majority of times when you alter the sys.path, you are trying to overcome a bad structure of your files. In other words, you can always avoid altering the sys.path variable by changing the structure of your source files inside your project.\nJust to be clear, is a bad idea to alter the sys.path inside the source code of your package. However, it is ok to alter these variables outside of your package.\nAs a practical example, the Apache Spark project (which is open source) is written in Scala, but have an API available to Python trough the pyspark package. If you look closely into the source code of the project, or, more specifically at the run-tests.py file, you can see that new paths (or new directories) are appended to sys.path.\nHowever, this run-tests.py file IS NOT PART of the pyspark package itself. It is just an auxiliary script (outside of the package) used to support the test processes of pyspark. This means that run-tests.py contains code that is not intended to be executed by the users, but by the developers of pyspark instead."
  },
  {
    "objectID": "posts/2023/2023-01-30-python-pckg/en/index.html#the-search-path-of-python",
    "href": "posts/2023/2023-01-30-python-pckg/en/index.html#the-search-path-of-python",
    "title": "What I learned from developing my first Python package",
    "section": "3.1 The search path of Python",
    "text": "3.1 The search path of Python\nWe usually import a package in Python, by including a import statement at the beginning of our script. For example, to import the pandas package to my Python session, I could do this:\n\nimport pandas\n\nWhen you import a package in Python, the Python interpreter starts a search process trough your computer, to find the specific package you called in your script. Every Python package you use must be installed in your machine. Otherwise, Python will never find it, and, as a consequence, you can not use it.\nThe Python interpreter will always look for the packages you import, inside a set of pre-defined locations of your computer. This pre-defined list is stored inside the sys.path variable2. In other words, when you import a package, Python looks for this package inside each one of the directories listed at sys.path variable.\n\nimport sys\nprint(sys.path)\n\n['/home/pedro/Documentos/Projetos/Personal-website/posts/2023/2023-01-30-python-pckg/en', '/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/home/pedro/.local/lib/python3.10/site-packages', '/usr/local/lib/python3.10/dist-packages', '/usr/lib/python3/dist-packages']\n\n\nYou might also find contents about the PYTHONPATH variable when searching for this subject on the internet. In essence, PYTHONPATH is a environment variable that can contain a complementary list of directories to be added to sys.path3.\nAs you can imagine, the Python interpreter look into these directories in a sequential manner. That is, Python looks for the package at the first folder. If it does not find the package you called, then, it looks at the second folder. If it does not find the package again, it looks at the third folder. And goes on and on, until it hits the last folder of the list.\nIf does not find the package you called at this last folder, Python will automatically raise a ModuleNotFoundError error. As you expect, this error means that Python could not find the package you called at any of the directories listed at sys.path."
  },
  {
    "objectID": "posts/2023/2023-01-30-python-pckg/en/index.html#structuring-the-package-was-one-of-the-hardest-parts",
    "href": "posts/2023/2023-01-30-python-pckg/en/index.html#structuring-the-package-was-one-of-the-hardest-parts",
    "title": "What I learned from developing my first Python package",
    "section": "3.4 Structuring the package was one of the hardest parts",
    "text": "3.4 Structuring the package was one of the hardest parts\nFrom what I researched, every Python package follows the same basic directory structure. In other words, the files that compose a Python package are structured in a standard way. But, understanding and using this structure effectively was one of the hardest parts for me.\nFor the most part, a Python package contains these files:\n\nLICENSE.md or LICENSE.rst (or both): a text file with the license of your package. It can be a Markdown file (.md), or, a reStructuredText markup file (.rst);\nREADME.md: a Markdown file introducing your package. That is, a file that describes succintly the objective of the package, its main features, and showing a small example of use of the package;\n\nAlso, a Python package usually contains these folders (or directories):\n\nsrc/<package-name>/ or <package-name>/: inside this directory you store all Python modules of your package, that is, the source code of your package;\ntests/: inside this directory you store all unit tests of your package. In other words, the scripts and automated workflow used to test your package.\n\n\nThe source code (or the python modules) of the package is always kept inside a folder with the same name as the package itself (i.e.¬†the <package-name>/ folder). So, for a package named spark_map we should keep the source files of this package inside a folder called spark_map. As a practical example, if you look at the source code of the pandas pacakge, you can see that the source code of the package is stored inside a folder called pandas.\nThis <package-name>/ folder might be (or might be not) inside another folder called src/, that is, the path to the source code might be src/<package-name>/ instead of <package-name>/. The pandas package for example, do not uses the src/ folder, so the source code is stored inside the pandas/ folder. In contrast, the famous flask package uses the flask/ folder inside a src/ folder, so the path to the source code becomes src/flask.\nSo the folder structure to store the source code of the package might change very slightly from package to package. But in general, the source is always stored inside a folder with the same name as the package (i.e.¬†the <package-name>/ folder).\nBesides these standard files, a Python package usually have one, two, or more files that control the build process of the package (like setup.py, pyproject.toml or setup.cfg). I talk more about these files at Section¬†3.5.\nFor example, a possible file strucuture for a package named as haven could be:\n.\n‚îú‚îÄ‚îÄ LICENSE.md\n‚îú‚îÄ‚îÄ LICENSE.rst\n‚îú‚îÄ‚îÄ README.md\n‚îú‚îÄ‚îÄ pyproject.toml\n‚îú‚îÄ‚îÄ src\n‚îÇ   ‚îî‚îÄ‚îÄ haven\n‚îÇ       ‚îú‚îÄ‚îÄ __init__.py\n‚îÇ       ‚îú‚îÄ‚îÄ functions.py\n‚îÇ       ‚îú‚îÄ‚îÄ utils.py \n‚îÇ       ‚îî‚îÄ‚îÄ haven.py\n‚îÇ\n‚îî‚îÄ‚îÄ tests\n    ‚îú‚îÄ‚îÄ test_functions.py\n    ‚îî‚îÄ‚îÄ test_haven.py"
  },
  {
    "objectID": "posts/2023/2023-01-30-python-pckg/en/index.html#different-build-systems-behave-differently",
    "href": "posts/2023/2023-01-30-python-pckg/en/index.html#different-build-systems-behave-differently",
    "title": "What I learned from developing my first Python package",
    "section": "Different build systems behave differently",
    "text": "Different build systems behave differently"
  },
  {
    "objectID": "posts/2023/2023-01-30-python-pckg/en/index.html#differences-between-a-package-and-a-module",
    "href": "posts/2023/2023-01-30-python-pckg/en/index.html#differences-between-a-package-and-a-module",
    "title": "What I learned from developing my first Python package",
    "section": "3.3 Differences between a package and a module",
    "text": "3.3 Differences between a package and a module\nThis is a very basic knowledge for a Python developer. However, until recently, I did not know the meaning of these two concepts. So, I will give it to you now, in case you do not have it yet.\nA Python module is a single Python file (i.e.¬†a file with extension .py). Every Python script you write, is a Python module. In contrast, a Python package is a set of Python modules gathered together inside a folder. This folder must contain a particular Python module named as __init__.py. This __init__.py file, is the file that ‚Äúinitialize‚Äù, or, ‚Äúidentifies‚Äù this folder as a Python package4.\nYou can have multiple Python packages inside a Python package. That is, inside the directory of your package, you can have multiple sub-directories with more Python modules and __init__.py files. In this case, these sub-directories become submodules of the package."
  },
  {
    "objectID": "posts/2023/2023-01-30-python-pckg/en/index.html#sec-build-systems",
    "href": "posts/2023/2023-01-30-python-pckg/en/index.html#sec-build-systems",
    "title": "What I learned from developing my first Python package",
    "section": "3.5 Different build systems behave differently",
    "text": "3.5 Different build systems behave differently"
  }
]